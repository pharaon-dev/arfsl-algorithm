{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f3eec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from copy import deepcopy\n",
    "import Cython\n",
    "import random\n",
    "from pprint import pprint\n",
    "import time\n",
    "from joblib import Parallel, delayed, parallel_backend, Memory\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "#import KFold\n",
    "from statistics import mean\n",
    "#from apriori_loss import *\n",
    "#from scikit.sklearn.tree import DecisionTreeClassifierLoss\n",
    "#from tree_update_loss.tree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8393136",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "235a96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "#Differents functions\n",
    "# spliting datas\n",
    "\n",
    "def train_test_split_(data, test_size):\n",
    "    \n",
    "    #check if test_size is a float\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(data))\n",
    "    \n",
    "    #retrieve all indices\n",
    "    indices = data.index.tolist()\n",
    "    \n",
    "    #select random indices according to test_size\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "    \n",
    "    #spliting datas in training & testing\n",
    "    test_data = data.loc[test_indices]\n",
    "    train_data = data.drop(test_indices)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "#Check data purity\n",
    "def check_purity(data):\n",
    "    #print(\"check purity : \", len(np.unique(data[:,-1])) == 1)\n",
    "    #Return purity value regarding to the number of unique classes\n",
    "    return  (False,True)[len(np.unique(data[:,-1])) == 1]\n",
    "    \n",
    "#Normal classification using majority\n",
    "def classify(data):\n",
    "    #get all classes & count occurences\n",
    "    label = data[:,-1]\n",
    "    uniques_classes, counts = np.unique(data[:,-1], return_counts = True)\n",
    "    \n",
    "    #get index of most common class\n",
    "    index = counts.argmax()\n",
    "    \n",
    "    #return the most common class\n",
    "    return uniques_classes[index]\n",
    "\n",
    "# Modified Classification using proposed approach\n",
    "def modified_classify(data, idx_montant, idx_taux, idx_nbe):\n",
    "    #initializing\n",
    "    P  = 0\n",
    "    M = 0\n",
    "    n_row , _ = data.shape\n",
    "    index_montant = idx_montant #13\n",
    "    index_taux = idx_taux #2\n",
    "    index_nbe = idx_nbe #4\n",
    "    for line in range(n_row):\n",
    "        if data[line,-1] == 0:\n",
    "            P += data[line,index_montant]\n",
    "        else:\n",
    "            M += (data[line, index_taux]/100) * data[line,index_montant] * data[line,index_nbe]/12\n",
    "        #print(\"({} , {})\".format(data[line,index_montant], data[line, index_taux]))\n",
    "    \n",
    "    #print(\"({}, {})\".format(P, M))\n",
    "    \n",
    "    return (0, 1)[M > P]\n",
    "        \n",
    "\n",
    "#Calculate all potential splits\n",
    "def get_splits(data, index_feature_not_selected, col_montant):\n",
    "    \n",
    "    #initialize our dict of potential splits\n",
    "    splits = {}\n",
    "    \n",
    "    #initialize all attribute potential splits list\n",
    "    _, n_cols = data.shape\n",
    "    #for col in range(n_cols - 1):\n",
    "    #    if col in index_feature_not_selected or col == col_montant:\n",
    "    #        continue\n",
    "    #    splits[col] = list()\n",
    "    \n",
    "    # Compute all attributes potential splits\n",
    "    for col in range(n_cols - 1):\n",
    "        #get unique datas\n",
    "        #print(\"Current col: {}\".format(col))\n",
    "        if col in index_feature_not_selected or col == col_montant:\n",
    "            continue\n",
    "\n",
    "        values = np.unique(data[:, col])\n",
    "        #print(\"values :\", values)\n",
    "        #populate our dict\n",
    "        feature_type = FEATURE_TYPES[col]\n",
    "        if feature_type == \"Continous\":\n",
    "            for index in range(1, len(values)):\n",
    "                if not col in splits:\n",
    "                    splits[col] = list()\n",
    "                current_value = values[index]\n",
    "                #print(current_value)\n",
    "                previous_value = values[index - 1]\n",
    "                potential_split = np.mean([current_value, previous_value])\n",
    "                splits[col].append(potential_split)\n",
    "        else:\n",
    "            splits[col] = values\n",
    "    #print(\"splits : \", splits)\n",
    "    return splits\n",
    "\n",
    "#Spliting data\n",
    "def split_data(data, feature_col, value):\n",
    "    \n",
    "    feature_type = FEATURE_TYPES[feature_col]\n",
    "    \n",
    "    #define all masks\n",
    "    \n",
    "    if feature_type == \"Continous\":\n",
    "        mask_inf = data[:, feature_col] <= value\n",
    "        mask_sup = data[:, feature_col] > value\n",
    "    else:\n",
    "        mask_inf = data[:, feature_col] == value\n",
    "        mask_sup = data[:, feature_col] != value\n",
    "    \n",
    "    #data spliting\n",
    "    if mask_inf.size == 0:\n",
    "        data_inf = np.array([])\n",
    "    else:\n",
    "        data_inf = data[mask_inf]\n",
    "        \n",
    "    if mask_sup.size == 0:\n",
    "        data_sup = np.array([])\n",
    "    else:\n",
    "        data_sup = data[mask_sup]\n",
    "\n",
    "    return data_inf, data_sup\n",
    "\n",
    "\n",
    "#Calculate chosen metric\n",
    "def calculate_metric(data, idx_montant, idx_taux, idx_nbe):\n",
    "     #get classes\n",
    "    label_class = data[:, -1]\n",
    "    #get counts for each class\n",
    "    _, counts = np.unique(label_class, return_counts=True)\n",
    "    \n",
    "    probabilities = counts / counts.sum()\n",
    "    \n",
    "    #computing metric value depending on the user choice\n",
    "    if METRIC == \"entropy\":\n",
    "        probabilities = counts / counts.sum()\n",
    "        computed_metric = sum(probabilities * -np.log2(probabilities))\n",
    "    elif METRIC == \"gini\":\n",
    "        probabilities **=2\n",
    "        computed_metric = 1- sum(probabilities)\n",
    "    elif METRIC == \"cs\":\n",
    "        #print(\"cs\")\n",
    "        P  = 0\n",
    "        M = 0\n",
    "        n_row , _ = data.shape\n",
    "        index_montant = idx_montant #13\n",
    "        index_taux = idx_taux #12\n",
    "        index_nbe = idx_nbe #4\n",
    "        for line in range(n_row):\n",
    "            if data[line,-1] == 0:\n",
    "                P += data[line,index_montant]\n",
    "            else:\n",
    "                M += (data[line, index_taux]/100) * data[line,index_montant] * data[line,index_nbe]/12\n",
    "        prod = np.prod(probabilities)\n",
    "        computed_metric = P*prod + M*prod\n",
    "    \n",
    "    return computed_metric\n",
    "\n",
    "# Overall metric value\n",
    "def overall_metric(data_inf, data_sup, idx_montant, idx_taux, idx_nbe):\n",
    "    data_all_lenght = len(data_inf) + len(data_sup)\n",
    "    \n",
    "    #compute overall metric value\n",
    "    \n",
    "    if len(data_inf) == 0:\n",
    "        metric_data_inf = 0\n",
    "    else:\n",
    "        metric_data_inf = (len(data_inf) / data_all_lenght) * calculate_metric(data_inf, idx_montant, idx_taux, idx_nbe)\n",
    "    \n",
    "    if len(data_sup) == 0:\n",
    "        metric_data_sup = 0\n",
    "    else:\n",
    "        metric_data_sup = (len(data_sup) / data_all_lenght) * calculate_metric(data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "\n",
    "    overall_metric= metric_data_inf + metric_data_sup\n",
    "    return overall_metric\n",
    "\n",
    "#Modified metric: Here the aim is to compute the total lost that we'll have\n",
    "def modified_metric(data, idx_montant, idx_taux, idx_nbe):\n",
    "    #initializing\n",
    "    P  = 0\n",
    "    M = 0\n",
    "    n_row , _ = data.shape\n",
    "    index_montant = idx_montant #13\n",
    "    index_taux = idx_taux #12\n",
    "    index_nbe = idx_nbe #4\n",
    "    for line in range(n_row):\n",
    "        if data[line,-1] == 0:\n",
    "            P += data[line,index_montant]\n",
    "        #else:\n",
    "            #M += (data[line, index_taux]/100) * data[line,index_montant] \n",
    "    #print(P)\n",
    "    return P\n",
    "\n",
    "#Compute our overall modified metric\n",
    "def overall_modified_metric(data_inf, data_sup, idx_montant, idx_taux, idx_nbe):\n",
    "    #get number of datas\n",
    "    data_all_lenght = len(data_inf) + len(data_sup)\n",
    "    \n",
    "    #compute overall metric value\n",
    "    metric_data_inf = (len(data_inf) / data_all_lenght)*modified_metric(data_inf, idx_montant, idx_taux, idx_nbe)\n",
    "    metric_data_sup = (len(data_sup) / data_all_lenght)*modified_metric(data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "    overall_metric= metric_data_inf + metric_data_sup\n",
    "    #print(\"({}, {})\".format(metric_data_inf, metric_data_sup))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "#parralelized function\n",
    "def computing_best_column(data, colum_index, value, idx_montant, idx_taux, idx_nbe):\n",
    "    \n",
    "    global best_split_column, best_split_value, overall_metric_value\n",
    "    \n",
    "    #print(\"current column: {}\".format(colum_index))\n",
    "    data_inf, data_sup = split_data(data, colum_index, value)\n",
    "    current_overall = overall_modified_metric(data_inf, data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "            #print(current_overall)\n",
    "            #check if lower\n",
    "    if current_overall <= overall_metric_value:\n",
    "        ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "        overall_metric_value = current_overall\n",
    "        best_split_column = colum_index\n",
    "        best_split_value = value\n",
    "        #print(\"Done !! bests: ({}, {}, {})\".format(best_split_column, best_split_value, overall_metric_value))\n",
    "\n",
    "#determine best split attribute and value\n",
    "def determine_best_split(data, potential_splits, idx_montant, idx_taux, idx_nbe):\n",
    "     \n",
    "    #print(potential_splits)\n",
    "    \n",
    "    #So let's implement parralel version of our super code\n",
    "    #Parallel(n_jobs=-1, require='sharedmem')(\n",
    "     #   delayed(func)(args)\n",
    "    #)\n",
    "    #global best_split_column, best_split_value, overall_metric_value\n",
    "    \n",
    "    #overall_metric_value = 300000000000000\n",
    "    overall_metric_value = float('inf')\n",
    "    #with Parallel(n_jobs=-1, backend=\"threading\", require=\"sharedmem\", verbose=5) as parallel:\n",
    "      #  parallel(delayed(computing_best_column)(data, colum_index, value) for colum_index in potential_splits for value in potential_splits[colum_index]) \n",
    "    best_split_columns = 0\n",
    "    best_split_value = 0\n",
    "    for colum_index in potential_splits:\n",
    "        #print(\"current column: {}\".format(colum_index))\n",
    "        for value in potential_splits[colum_index]:\n",
    "            #print(\"current value: {}\".format(value))\n",
    "            data_inf, data_sup = split_data(data, colum_index, value)\n",
    "            current_overall = overall_metric(data_inf, data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "            #print(current_overall)\n",
    "            #check if lower\n",
    "            if current_overall <= overall_metric_value:\n",
    "                ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "                overall_metric_value = current_overall\n",
    "                best_split_columns = colum_index\n",
    "                best_split_value = value\n",
    "    #print(best_split_value)\n",
    "    #Loop over all datas, calculate overall_entropy, and update if it's lower\n",
    "    \n",
    "    #print(\"Final Done !! bests: ({}, {}, {})\".format(best_split_columns, best_split_value, overall_metric_value))\n",
    "    return best_split_columns, best_split_value, overall_metric_value\n",
    "\n",
    "#building decision Tree\n",
    "def decision_tree(df, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter=0, min_samples=5, max_depth=5, metric=\"entropy\"):\n",
    "    \n",
    "    if counter == 0:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            data = df.values\n",
    "        else: \n",
    "            data = df\n",
    "        global COLUMNS_NAMES, FEATURE_TYPES, METRIC\n",
    "        COLUMNS_NAMES = df.columns[:-1]\n",
    "        FEATURE_TYPES = determine_feature_types(df)\n",
    "        METRIC = metric\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    #base case\n",
    "    potential_splits = get_splits(data, index_feature_not_selected, idx_montant)\n",
    "    #print(potential_splits)\n",
    "    if check_purity(data) or (len(data) < min_samples) or (counter == max_depth) or potential_splits == {}:\n",
    "        classification = modified_classify(data, idx_montant, idx_taux, idx_nbe)\n",
    "        return classification\n",
    "    \n",
    "    else:\n",
    "        counter +=1\n",
    "        #computations for right and left part \n",
    "        best_split_column, best_split_value, overall_metric_value = determine_best_split(data, potential_splits, idx_montant, idx_taux, idx_nbe)\n",
    "        \n",
    "        #We must change data_inf & data_sup order later\n",
    "        data_inf, data_sup = split_data(data, best_split_column, best_split_value)\n",
    "        \n",
    "        # Creating subTree\n",
    "        feature_type = FEATURE_TYPES[best_split_column]    \n",
    "        if feature_type == \"Continous\":\n",
    "            question = \"{} <= {}\".format(COLUMNS_NAMES[best_split_column], best_split_value)\n",
    "        else:\n",
    "            question = \"{} == {}\".format(COLUMNS_NAMES[best_split_column], best_split_value)\n",
    "        #Adding labels\n",
    "        labels = \" \" + str(len(data_inf) + len(data_sup)) + \" \" + str(overall_metric_value)\n",
    "        question += labels\n",
    "        sub_tree = {question: []}\n",
    "        ###print(question)            \n",
    "        #index_feature_not_selected.append(best_split_column)\n",
    "        #left and right\n",
    "        yes_answer = decision_tree(data_inf, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter, min_samples, max_depth, metric=METRIC)\n",
    "        no_answer = decision_tree(data_sup, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter, min_samples, max_depth, metric=METRIC)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            ###print(yes_answer)\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            #Append left and right part\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree\n",
    "        \n",
    "#classify a sample\n",
    "def classify_sample(sample, tree):\n",
    "    \n",
    "    #get node elements\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    key = list(tree.keys())[0]\n",
    "    #print(key.split())\n",
    "    feature, comp_op, value, _, _ = key.split()\n",
    "    \n",
    "    if comp_op == \"<=\":\n",
    "        if sample[feature] <= float(value):\n",
    "            answer = tree[key][0]\n",
    "        else:\n",
    "            answer = tree[key][1]\n",
    "    else:\n",
    "        if str(sample[feature]) == value:\n",
    "            answer = tree[key][0]\n",
    "        else:\n",
    "            answer = tree[key][1]\n",
    "        \n",
    "    #test base case\n",
    "    if not isinstance(answer, dict):\n",
    "        #print('yes')\n",
    "        return answer\n",
    "    else:\n",
    "        return classify_sample(sample, answer)\n",
    "\n",
    "#compute accuracy\n",
    "def my_accuracy(df, tree, classe):\n",
    "    \n",
    "    df[\"classification\"] = df.apply(classify_sample, axis=1, args=(tree,))\n",
    "    df[\"classification_correct\"] = df.classification == df[classe]\n",
    "    \n",
    "    accuracy = df.classification_correct.mean()\n",
    "    \n",
    "    return accuracy, df\n",
    "    \n",
    "\n",
    "# In order to handle non-continous values\n",
    "# We have to identify all features type in our dataset\n",
    "def determine_feature_types(data):\n",
    "    \n",
    "    features_type  = []\n",
    "    threshold = 931\n",
    "    for col in data.columns:\n",
    "        \n",
    "        uniques_val = data[col].unique()\n",
    "        sample = uniques_val[0]\n",
    "        \n",
    "        if (isinstance(sample, str)):\n",
    "            features_type.append(\"Categorical\")\n",
    "        else:\n",
    "            features_type.append(\"Continous\")\n",
    "    \n",
    "    return features_type\n",
    "\n",
    "\n",
    "def compute_metrics(df, name_classe, name_montant, name_taux, name_duree):    \n",
    "    # 1- Accuracy\n",
    "    accuracy = df.classification_correct.mean()\n",
    "    \n",
    "    #2- Recall, precision\n",
    "    TP = len(df[(df[name_classe] == 1) & (df.classification == 1)])\n",
    "    FP = len(df[(df[name_classe] == 0) & (df.classification == 1)])\n",
    "    FN = len(df[(df[name_classe] == 1) & (df.classification == 0)])\n",
    "    TN = len(df[(df[name_classe] == 0) & (df.classification == 0)])\n",
    "    \n",
    "    if TP == 0 and FP == 0:\n",
    "        Precision = 0.0\n",
    "    else:\n",
    "        Precision = TP / (TP + FP)\n",
    "    if TP == 0 and FN == 0:\n",
    "        Recall = 0.0\n",
    "    else:\n",
    "        Recall = TP / (TP + FN)\n",
    "    Precision, Recall\n",
    "    \n",
    "    #3- Lost, no_win\n",
    "    #Computing new matrix confusion values\n",
    "    P = df[name_montant][(df[name_classe] == 0) & (df.classification == 1)].sum()\n",
    "\n",
    "    df_no_win = df[[name_montant, name_taux, name_duree]][(df[name_classe] == 1) & (df.classification == 0)]\n",
    "    df_no_win[name_taux] /=100\n",
    "    df_no_win[\"NoWin\"] = df_no_win[name_montant] * df_no_win[name_taux] * df_no_win[name_duree]/12\n",
    "\n",
    "    M = df_no_win.NoWin.sum()\n",
    "    P, M\n",
    "    computed_metric = P + M\n",
    "    # Error\n",
    "    #error = (FP / (TP + FP)) + (FN / FN + TN)\n",
    "    \n",
    "    \n",
    "    #label_class = list(df[name_classe])\n",
    "    #get counts for each class\n",
    "    #_, counts = np.unique(label_class, return_counts=True)\n",
    "    \n",
    "    #probabilities = counts / counts.sum()\n",
    "    \n",
    "    #prod = np.prod(probabilities)\n",
    "    #computed_metric = P*prod + M*prod\n",
    "        \n",
    "    #Friedman Test\n",
    "    #f, _ = friedmanchisquare(df.kredit.values, df.classification.values)\n",
    "    \n",
    "    #resulting metric list\n",
    "    result = [(accuracy, Precision, Recall), (P, M), (TP, FP, FN, TN)]\n",
    "    \n",
    "    return result, computed_metric\n",
    "\n",
    "def inverse(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree):    \n",
    "    # 1- Accuracy\n",
    "    accuracy = df.classification_correct.mean()\n",
    "    \n",
    "    #2- Recall, precision\n",
    "    set_tp = df[(df[name_classe] == 1) & (df.classification == 1)]\n",
    "    set_fp = df[(df[name_classe] == 0) & (df.classification == 1)]\n",
    "    set_fn = df[(df[name_classe] == 1) & (df.classification == 0)]\n",
    "    set_tn = df[(df[name_classe] == 0) & (df.classification == 0)]\n",
    "    \n",
    "    \n",
    "    TP = len(set_tp)\n",
    "    FP = len(set_fp)\n",
    "    FN = len(set_fn)\n",
    "    TN = len(set_tn)\n",
    "    \n",
    "    #print(\"TP : \", TP)\n",
    "    #print(\"FP : \", FP)\n",
    "    #print(\"FN : \", FN)\n",
    "    #print(\"TN : \", TN)\n",
    "    \n",
    "    cout_tp = sum(set_tp[name_montant] * (set_tp[name_taux] / 100) * set_tp[name_duree] / 12)\n",
    "    cout_tn = sum(set_tn[name_montant] * (1-alpha))\n",
    "    cout_fp = sum(set_fp[name_montant] * (1-alpha))#-\n",
    "    cout_fn = sum(set_fn[name_montant] * (set_fn[name_taux] / 100) * set_fn[name_duree] / 12)#-\n",
    "    \n",
    "    \n",
    "    cout = 0.0\n",
    "    if type_cout == \"total\":\n",
    "        cout_to = cout_tp - cout_fp - cout_fn + cout_tn\n",
    "    elif type_cout == \"optimiste\":\n",
    "        cout_op = cout_tp + cout_tn\n",
    "    elif type_cout == \"pessimiste\":\n",
    "        cout_pe = cout_fn + cout_fp\n",
    "    elif type_cout == \"reel\":\n",
    "        cout_re = cout_tp + cout_fp\n",
    "    \n",
    "    #df_v = df.copy()\n",
    "    #df_v[\"inverse\"] = df_v[name_classe].apply(inverse)\n",
    "    #set_fp = df_v[(df_v[name_classe] == 0) & (df_v['inverse'] == 1)]\n",
    "    #set_fn = df_v[(df_v[name_classe] == 1) & (df_v['inverse'] == 0)]\n",
    "    #cout_fp = sum(set_fp[name_montant] * (1-alpha))#-\n",
    "    #cout_fn = sum(set_fn[name_montant] * (set_fn[name_taux] / 100) * set_fn[name_duree] / 12)\n",
    "    #s_all = cout_fn + cout_fp\n",
    "    \n",
    "    \n",
    "    #cout = (cout_tp + cout_tn)/(cout_tp + cout_tn - cout_fp - cout_fn)\n",
    "    #cout = cout_pe/s_all\n",
    "    cout = cout_pe\n",
    "    if TP == 0 and FP == 0:\n",
    "        Precision = 0.0\n",
    "    else:\n",
    "        Precision = TP / (TP + FP)\n",
    "    if TP == 0 and FN == 0:\n",
    "        Recall = 0.0\n",
    "    else:\n",
    "        Recall = TP / (TP + FN)\n",
    "        \n",
    "    #resulting metric list\n",
    "    result = (cout_pe, accuracy, Precision, Recall)\n",
    "    \n",
    "    return result, cout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_feature_select_tree(my_tree):\n",
    "    j = 0\n",
    "    stock_tree = []\n",
    "    list_key = []\n",
    "    stock_tree.append(my_tree)\n",
    "    while j <= len(stock_tree)-1:\n",
    "        #print(stock_tree)\n",
    "        tree = stock_tree[j]\n",
    "        if type(tree) is dict:\n",
    "            for key, value in tree.items():\n",
    "                list_key.append(key)\n",
    "                if type(value[0]) is dict:\n",
    "                    stock_tree.append(value[0])\n",
    "                if type(value[1]) is dict:\n",
    "                    stock_tree.append(value[1])\n",
    "        j += 1   \n",
    "    for i in range(len(list_key)):\n",
    "        list_key[i] = list_key[i].split(\" \")[0]\n",
    "    list_key = list(set(list_key))\n",
    "\n",
    "    return list_key\n",
    "\n",
    "\n",
    "#determine_feature_types -- ok\n",
    "#modified_classify -- not ok\n",
    "#get_splits -- ok\n",
    "#determine_best_split \n",
    "#split_data -- ok\n",
    "#overall_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a34cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_purity_1(data):\n",
    "    #print(\"check purity : \", len(np.unique(data[:,-1])) == 1)\n",
    "    #Return purity value regarding to the number of unique classes\n",
    "    return  (False,True)[len(np.unique(data[:,-1])) == 1]\n",
    "    \n",
    "#Normal classification using majority\n",
    "def classify_1(data, index_montant):\n",
    "    #get all classes & count occurences\n",
    "    M = sum(data[data[:,-1] == 1, index_montant])\n",
    "    P = sum(data[data[:,-1] == 0, index_montant])\n",
    "    #get index of most common class\n",
    "    #return the most common class\n",
    "    return (0, 1)[M > P]\n",
    "\n",
    "def modified_classify_update_1(data, idx_montant, idx_taux, idx_nbe):\n",
    "    #initializing\n",
    "    P  = 0\n",
    "    M = 0\n",
    "    n_row , _ = data.shape\n",
    "    index_montant = idx_montant #13\n",
    "    index_taux = idx_taux #2\n",
    "    index_nbe = idx_nbe #4\n",
    "    for line in range(n_row):\n",
    "        if data[line,-1] == 0:\n",
    "            P += data[line,index_montant]\n",
    "        else:\n",
    "            M += (data[line, index_taux]/100) * data[line,index_montant] * data[line,index_nbe]/12\n",
    "        #print(\"({} , {})\".format(data[line,index_montant], data[line, index_taux]))\n",
    "    \n",
    "    #print(\"({}, {})\".format(P, M))\n",
    "    \n",
    "    return (0, 1)[M > P]\n",
    "\n",
    "\n",
    "# Modified Classification using proposed approach\n",
    "def modified_classify_1(data, idx_montant, idx_taux, idx_nbe):\n",
    "    #initializing\n",
    "    M = sum(data[data[:,-1] == 1, idx_montant])\n",
    "    P = sum(data[data[:,-1] == 0, idx_montant])\n",
    "    return (0, 1)[M > P]\n",
    "\n",
    "\n",
    "#Calculate all potential splits\n",
    "def get_splits_1(data, index_feature_not_selected, col_montant):\n",
    "    \n",
    "    #initialize our dict of potential splits\n",
    "    splits = {}\n",
    "    \n",
    "    #initialize all attribute potential splits list\n",
    "    _, n_cols = data.shape\n",
    "    #for col in range(n_cols - 1):\n",
    "    #    if col in index_feature_not_selected or col == col_montant:\n",
    "    #        continue\n",
    "    #    splits[col] = list()\n",
    "    \n",
    "    # Compute all attributes potential splits\n",
    "    for col in range(n_cols - 1):\n",
    "        #get unique datas\n",
    "        #print(\"Current col: {}\".format(col))\n",
    "        if col in index_feature_not_selected or col == col_montant:\n",
    "            continue\n",
    "\n",
    "        values = np.unique(data[:, col])\n",
    "        #print(\"values :\", values)\n",
    "        #populate our dict\n",
    "        feature_type = FEATURE_TYPES_1[col]\n",
    "        if feature_type == \"Continous\":\n",
    "            for index in range(1, len(values)):\n",
    "                if not col in splits:\n",
    "                    splits[col] = list()\n",
    "                current_value = values[index]\n",
    "                #print(current_value)\n",
    "                previous_value = values[index - 1]\n",
    "                potential_split = np.mean([current_value, previous_value])\n",
    "                splits[col].append(potential_split)\n",
    "        else:\n",
    "            splits[col] = values\n",
    "    #print(\"splits : \", splits)\n",
    "    return splits\n",
    "\n",
    "#Spliting data\n",
    "def split_data_1(data, feature_col, value):\n",
    "    \n",
    "    feature_type = FEATURE_TYPES_1[feature_col]\n",
    "    \n",
    "    #define all masks\n",
    "    \n",
    "    if feature_type == \"Continous\":\n",
    "        mask_inf = data[:, feature_col] <= value\n",
    "        mask_sup = data[:, feature_col] > value\n",
    "    else:\n",
    "        mask_inf = data[:, feature_col] == value\n",
    "        mask_sup = data[:, feature_col] != value\n",
    "    \n",
    "    #data spliting\n",
    "    if mask_inf.size == 0:\n",
    "        data_inf = np.array([])\n",
    "    else:\n",
    "        data_inf = data[mask_inf]\n",
    "        \n",
    "    if mask_sup.size == 0:\n",
    "        data_sup = np.array([])\n",
    "    else:\n",
    "        data_sup = data[mask_sup]\n",
    "    \n",
    "    return data_inf, data_sup\n",
    "\n",
    "\n",
    "#Calculate chosen metric\n",
    "def calculate_metric_1(data, idx_montant, idx_taux, idx_nbe):\n",
    "     #get classes\n",
    "    label_class = data[:, -1]\n",
    "    #get counts for each class\n",
    "    label, counts = np.unique(label_class, return_counts=True)\n",
    "    computed_metric = 0.0\n",
    "    if len(label) != 0:\n",
    "        n_row , _ = data.shape\n",
    "        counts_loss = np.zeros(len(label))\n",
    "        for i in range(len(label)):\n",
    "            data_label = data[data[:, -1] == label[i],:]\n",
    "            counts_loss[i] = sum(data_label[:, idx_montant])\n",
    "        #sum_counts_loss = sum(counts_loss)\n",
    "        #for i in range(len(counts_loss)):\n",
    "        #    counts_loss[i] /= sum_counts_loss \n",
    "        #probabilities_loss = counts_loss\n",
    "        probabilities_loss = counts_loss / counts_loss.sum()\n",
    "        #computing metric value depending on the user choice\n",
    "        if METRIC_1 == \"entropy\":\n",
    "            #probabilities = counts / counts.sum()\n",
    "            computed_metric = sum(probabilities_loss * -np.log2(probabilities_loss))\n",
    "        elif METRIC_1 == \"gini\":\n",
    "            probabilities_loss **=2\n",
    "            computed_metric = 1 - sum(probabilities_loss)\n",
    "        elif METRIC_1 == \"cs\":\n",
    "            #print(\"cs\")\n",
    "            P  = 0\n",
    "            M = 0\n",
    "            n_row , _ = data.shape\n",
    "            index_montant = idx_montant #13\n",
    "            index_taux = idx_taux #12\n",
    "            index_nbe = idx_nbe #4\n",
    "            for line in range(n_row):\n",
    "                if data[line,-1] == 0:\n",
    "                    P += data[line,index_montant]\n",
    "                else:\n",
    "                    M += (data[line, index_taux]/100) * data[line,index_montant] * data[line,index_nbe]/12\n",
    "            prod = np.prod(probabilities_loss)\n",
    "            computed_metric = P*prod + M*prod\n",
    "    \n",
    "    return computed_metric\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metric_update_1(data, idx_montant, idx_taux, idx_nbe):\n",
    "    \n",
    "    label_class = data[:, -1]\n",
    "    #get counts for each class\n",
    "    label, counts = np.unique(label_class, return_counts=True)\n",
    "    computed_metric = 0.0\n",
    "    if len(label) != 0:    \n",
    "        P  = 0\n",
    "        M = 0\n",
    "        n_row , _ = data.shape\n",
    "        index_montant = idx_montant #13\n",
    "        index_taux = idx_taux #12\n",
    "        index_nbe = idx_nbe #4\n",
    "        label, _ = np.unique(data[:, - 1], return_counts=True)\n",
    "        counts_loss = np.zeros(2)\n",
    "        for line in range(n_row):\n",
    "            if data[line,-1] == 0:\n",
    "                P += data[line,index_montant]\n",
    "            else:\n",
    "                M += (data[line, index_taux]/100) * data[line,index_montant] * data[line,index_nbe]/12\n",
    "        \n",
    "        for i in label:\n",
    "            if int(i) == 0:\n",
    "                counts_loss[int(i)] = P\n",
    "            else:\n",
    "                counts_loss[int(i)] = M\n",
    "        probabilities_loss = counts_loss / counts_loss.sum()\n",
    "        #computing metric value depending on the user choice\n",
    "        if METRIC_1 == \"entropy\":\n",
    "            #probabilities = counts / counts.sum()\n",
    "            computed_metric = sum(probabilities_loss * -np.log2(probabilities_loss))\n",
    "        elif METRIC_1 == \"gini\":\n",
    "            probabilities_loss **=2\n",
    "            computed_metric = 1 - sum(probabilities_loss)    \n",
    "    return computed_metric\n",
    "\n",
    "# Overall metric value\n",
    "def overall_metric_1(data_inf, data_sup, idx_montant, idx_taux, idx_nbe):\n",
    "    inf_loss = sum(data_inf[:, idx_montant])\n",
    "    sup_loss = sum(data_sup[:, idx_montant])\n",
    "    \n",
    "    data_all_lenght_loss = inf_loss + sup_loss\n",
    "    \n",
    "    #compute overall metric value\n",
    "    if inf_loss == 0:\n",
    "        metric_data_inf = 0\n",
    "    else:\n",
    "        metric_data_inf = (inf_loss / data_all_lenght_loss) * calculate_metric_update_1(data_inf, idx_montant, idx_taux, idx_nbe)\n",
    "    \n",
    "    if sup_loss == 0:\n",
    "        metric_data_sup = 0\n",
    "    else:\n",
    "        metric_data_sup = (sup_loss / data_all_lenght_loss) * calculate_metric_update_1(data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "        \n",
    "    overall_metric= metric_data_inf + metric_data_sup\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "#determine best split attribute and value\n",
    "def determine_best_split_1(data, potential_splits, idx_montant, idx_taux, idx_nbe):\n",
    "     \n",
    "    #print(potential_splits)\n",
    "    \n",
    "    #So let's implement parralel version of our super code\n",
    "    #Parallel(n_jobs=-1, require='sharedmem')(\n",
    "     #   delayed(func)(args)\n",
    "    #)\n",
    "    #global best_split_column, best_split_value, overall_metric_value\n",
    "    \n",
    "    #overall_metric_value = 300000000000000\n",
    "    overall_metric_value = float('inf')\n",
    "    #with Parallel(n_jobs=-1, backend=\"threading\", require=\"sharedmem\", verbose=5) as parallel:\n",
    "      #  parallel(delayed(computing_best_column)(data, colum_index, value) for colum_index in potential_splits for value in potential_splits[colum_index]) \n",
    "    best_split_columns = 0\n",
    "    best_split_value = 0\n",
    "    for colum_index in potential_splits:\n",
    "        #print(\"current column: {}\".format(colum_index))\n",
    "        for value in potential_splits[colum_index]:\n",
    "            #print(\"current value: {}\".format(value))\n",
    "            data_inf, data_sup = split_data_1(data, colum_index, value)\n",
    "            current_overall = overall_metric_1(data_inf, data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "            #print(current_overall)\n",
    "            #check if lower\n",
    "            if current_overall <= overall_metric_value:\n",
    "                ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "                overall_metric_value = current_overall\n",
    "                best_split_columns = colum_index\n",
    "                best_split_value = value\n",
    "    #print(best_split_value)\n",
    "    #Loop over all datas, calculate overall_entropy, and update if it's lower\n",
    "    \n",
    "    #print(\"Final Done !! bests: ({}, {}, {})\".format(best_split_columns, best_split_value, overall_metric_value))\n",
    "    return best_split_columns, best_split_value, overall_metric_value\n",
    "\n",
    "#building decision Tree\n",
    "def decision_tree_1(df, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter=0, min_samples=5, max_depth=5, metric=\"entropy\"):\n",
    "    \n",
    "    if counter == 0:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            data = df.values\n",
    "        else: \n",
    "            data = df\n",
    "        global COLUMNS_NAMES_1, FEATURE_TYPES_1, METRIC_1\n",
    "        COLUMNS_NAMES_1 = df.columns[:-1]\n",
    "        FEATURE_TYPES_1 = determine_feature_types(df)\n",
    "        METRIC_1 = metric\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    #base case\n",
    "    potential_splits = get_splits_1(data, index_feature_not_selected, idx_montant)\n",
    "    #print(potential_splits)\n",
    "    if check_purity_1(data) or (len(data) < min_samples) or (counter == max_depth) or potential_splits == {}:\n",
    "        classification = modified_classify_update_1(data, idx_montant, idx_taux, idx_nbe)\n",
    "        return classification\n",
    "    \n",
    "    else:\n",
    "        counter +=1\n",
    "        #computations for right and left part \n",
    "        best_split_column, best_split_value, overall_metric_value = determine_best_split_1(data, potential_splits, idx_montant, idx_taux, idx_nbe)\n",
    "        \n",
    "        #We must change data_inf & data_sup order later\n",
    "        data_inf, data_sup = split_data_1(data, best_split_column, best_split_value)\n",
    "        \n",
    "        # Creating subTree\n",
    "        feature_type = FEATURE_TYPES_1[best_split_column]    \n",
    "        if feature_type == \"Continous\":\n",
    "            question = \"{} <= {}\".format(COLUMNS_NAMES_1[best_split_column], best_split_value)\n",
    "        else:\n",
    "            question = \"{} == {}\".format(COLUMNS_NAMES_1[best_split_column], best_split_value)\n",
    "        #Adding labels\n",
    "        labels = \" \" + str(len(data_inf) + len(data_sup)) + \" \" + str(overall_metric_value)\n",
    "        question += labels\n",
    "        sub_tree = {question: []}\n",
    "        ###print(question)            \n",
    "        \n",
    "        #left and right\n",
    "        yes_answer = decision_tree_1(data_inf, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter, min_samples, max_depth, metric=METRIC_1)\n",
    "        no_answer = decision_tree_1(data_sup, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter, min_samples, max_depth, metric=METRIC_1)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            ###print(yes_answer)\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            #Append left and right part\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b17bbd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_purity_2(data):\n",
    "    #print(\"check purity : \", len(np.unique(data[:,-1])) == 1)\n",
    "    #Return purity value regarding to the number of unique classes\n",
    "    return  (False,True)[len(np.unique(data[:,-1])) == 1]\n",
    "    \n",
    "#Normal classification using majority\n",
    "def classify_2(data):\n",
    "    #get all classes & count occurences\n",
    "    label = data[:,-1]\n",
    "    uniques_classes, counts = np.unique(data[:,-1], return_counts = True)\n",
    "    \n",
    "    #get index of most common class\n",
    "    index = counts.argmax()\n",
    "    \n",
    "    #return the most common class\n",
    "    return uniques_classes[index]\n",
    "\n",
    "# Modified Classification using proposed approach\n",
    "def modified_classify_2(data, idx_montant, idx_taux, idx_nbe):\n",
    "    #initializing\n",
    "    P  = 0\n",
    "    M = 0\n",
    "    n_row , _ = data.shape\n",
    "    index_montant = idx_montant #13\n",
    "    index_taux = idx_taux #2\n",
    "    index_nbe = idx_nbe #4\n",
    "    for line in range(n_row):\n",
    "        if data[line,-1] == 0:\n",
    "            P += data[line,index_montant]\n",
    "        else:\n",
    "            M += (data[line, index_taux]/100) * data[line,index_montant] * data[line,index_nbe]/12\n",
    "        #print(\"({} , {})\".format(data[line,index_montant], data[line, index_taux]))\n",
    "    \n",
    "    return (0, 1)[M > P]       \n",
    "\n",
    "#Calculate all potential splits\n",
    "def get_splits_2(data, index_feature_not_selected, col_montant):\n",
    "    \n",
    "    #initialize our dict of potential splits\n",
    "    splits = {}\n",
    "    \n",
    "    #initialize all attribute potential splits list\n",
    "    _, n_cols = data.shape\n",
    "    #for col in range(n_cols - 1):\n",
    "    #    if col in index_feature_not_selected or col == col_montant:\n",
    "    #        continue\n",
    "    #    splits[col] = list()\n",
    "    \n",
    "    # Compute all attributes potential splits\n",
    "    for col in range(n_cols - 1):\n",
    "        #get unique datas\n",
    "        #print(\"Current col: {}\".format(col))\n",
    "        if col in index_feature_not_selected or col == col_montant:\n",
    "            continue\n",
    "\n",
    "        values = np.unique(data[:, col])\n",
    "        #print(\"values :\", values)\n",
    "        #populate our dict\n",
    "        feature_type = FEATURE_TYPES_2[col]\n",
    "        if feature_type == \"Continous\":\n",
    "            for index in range(1, len(values)):\n",
    "                if not col in splits:\n",
    "                    splits[col] = list()\n",
    "                current_value = values[index]\n",
    "                #print(current_value)\n",
    "                previous_value = values[index - 1]\n",
    "                potential_split = np.mean([current_value, previous_value])\n",
    "                splits[col].append(potential_split)\n",
    "        else:\n",
    "            splits[col] = values\n",
    "    #print(\"splits : \", splits)\n",
    "    return splits\n",
    "\n",
    "#Spliting data\n",
    "def split_data_2(data, feature_col, value):\n",
    "    \n",
    "    feature_type = FEATURE_TYPES_2[feature_col]\n",
    "    \n",
    "    #define all masks\n",
    "    \n",
    "    if feature_type == \"Continous\":\n",
    "        mask_inf = data[:, feature_col] <= value\n",
    "        mask_sup = data[:, feature_col] > value\n",
    "    else:\n",
    "        mask_inf = data[:, feature_col] == value\n",
    "        mask_sup = data[:, feature_col] != value\n",
    "    \n",
    "    #data spliting\n",
    "    if mask_inf.size == 0:\n",
    "        data_inf = np.array([])\n",
    "    else:\n",
    "        data_inf = data[mask_inf]\n",
    "        \n",
    "    if mask_sup.size == 0:\n",
    "        data_sup = np.array([])\n",
    "    else:\n",
    "        data_sup = data[mask_sup]\n",
    "    \n",
    "    return data_inf, data_sup\n",
    "\n",
    "\n",
    "#Calculate chosen metric\n",
    "def calculate_metric_2(matrix_conf):\n",
    "    if METRIC_2 == \"total\":\n",
    "        computed_metric = matrix_conf[0][0] - matrix_conf[1][0] - matrix_conf[0][1] + matrix_conf[1][1]\n",
    "    elif METRIC_2 == \"pessimiste\":\n",
    "        computed_metric = matrix_conf[1][0] + matrix_conf[0][1]\n",
    "    elif METRIC_2 == \"optimiste\":\n",
    "        computed_metric = matrix_conf[0][0] + matrix_conf[1][1]\n",
    "    elif METRIC_2 == \"reel\":\n",
    "        computed_metric = matrix_conf[0][0] - matrix_conf[1][0]\n",
    "    \n",
    "    return computed_metric\n",
    "\n",
    "# Overall metric value\n",
    "def overall_metric_2(data_inf, data_sup, classe_maj_inf, classe_maj_sup, idx_montant, idx_taux, idx_nbe):\n",
    "    matrix_conf = np.zeros((2,2))\n",
    "    data_inf_0 = data_inf[data_inf[:, -1] == 0,:]\n",
    "    data_inf_1 = data_inf[data_inf[:, -1] == 1,:]\n",
    "    \n",
    "    data_sup_0 = data_sup[data_sup[:, -1] == 0,:]\n",
    "    data_sup_1 = data_sup[data_sup[:, -1] == 1,:]\n",
    "    \n",
    "    \n",
    "    if classe_maj_inf == 0:\n",
    "        matrix_conf[0][classe_maj_inf] = sum(data_inf_0[:, idx_montant]) * (1.0 - ALPHA_2)\n",
    "        matrix_conf[1][classe_maj_inf] = sum(data_inf_1[:, idx_montant] * (data_inf_1[:, idx_taux] / 100) * (data_inf_1[:, idx_nbe] / 12))# -\n",
    "        matrix_conf[0][classe_maj_sup] = sum(data_sup_0[:, idx_montant]) * (1.0 - ALPHA_2)# -\n",
    "        matrix_conf[1][classe_maj_sup] = sum(data_sup_1[:, idx_montant] * (data_sup_1[:, idx_taux] / 100) * (data_sup_1[:, idx_nbe] / 12))\n",
    "    else:\n",
    "        matrix_conf[0][classe_maj_inf] = sum(data_inf_0[:, idx_montant]) * (1.0 - ALPHA_2)# -\n",
    "        matrix_conf[1][classe_maj_inf] = sum(data_inf_1[:, idx_montant] * (data_inf_1[:, idx_taux] / 100) * (data_inf_1[:, idx_nbe] / 12))\n",
    "        matrix_conf[0][classe_maj_sup] = sum(data_sup_0[:, idx_montant]) * (1.0 - ALPHA_2)\n",
    "        matrix_conf[1][classe_maj_sup] = sum(data_sup_1[:, idx_montant] * (data_sup_1[:, idx_taux] / 100) * (data_sup_1[:, idx_nbe] / 12))#-\n",
    "    \n",
    "    return calculate_metric_2(matrix_conf)\n",
    "\n",
    "def overall_metric_update_2(data_inf, data_sup, classe_maj_inf, classe_maj_sup, idx_montant, idx_taux, idx_nbe):\n",
    "    \n",
    "    if classe_maj_inf != classe_maj_sup:\n",
    "        matrix_conf = np.zeros((2,2))\n",
    "        data_inf_0 = data_inf[data_inf[:, -1] == 0,:]\n",
    "        data_inf_1 = data_inf[data_inf[:, -1] == 1,:]\n",
    "\n",
    "        data_sup_0 = data_sup[data_sup[:, -1] == 0,:]\n",
    "        data_sup_1 = data_sup[data_sup[:, -1] == 1,:]\n",
    "        \n",
    "        n_row_inf_0 , _ = data_inf_0.shape\n",
    "        n_row_inf_1 , _ = data_inf_1.shape\n",
    "        n_row_sup_0 , _ = data_sup_0.shape\n",
    "        n_row_sup_1 , _ = data_sup_1.shape\n",
    "\n",
    "\n",
    "        if classe_maj_inf == 0:\n",
    "            matrix_conf[0][classe_maj_inf] = sum(data_inf_0[:, idx_montant]) * (1.0 - ALPHA_2)\n",
    "            matrix_conf[1][classe_maj_inf] = sum(data_inf_1[:, idx_montant] * (data_inf_1[:, idx_taux] / 100) * (data_inf_1[:, idx_nbe] / 12))# -\n",
    "            matrix_conf[0][classe_maj_sup] = sum(data_sup_0[:, idx_montant]) * (1.0 - ALPHA_2)# -\n",
    "            matrix_conf[1][classe_maj_sup] = sum(data_sup_1[:, idx_montant] * (data_sup_1[:, idx_taux] / 100) * (data_sup_1[:, idx_nbe] / 12))\n",
    "        else:\n",
    "            matrix_conf[0][classe_maj_inf] = sum(data_inf_0[:, idx_montant]) * (1.0 - ALPHA_2)# -\n",
    "            matrix_conf[1][classe_maj_inf] = sum(data_inf_1[:, idx_montant] * (data_inf_1[:, idx_taux] / 100) * (data_inf_1[:, idx_nbe] / 12))\n",
    "            matrix_conf[0][classe_maj_sup] = sum(data_sup_0[:, idx_montant]) * (1.0 - ALPHA_2)\n",
    "            matrix_conf[1][classe_maj_sup] = sum(data_sup_1[:, idx_montant] * (data_sup_1[:, idx_taux] / 100) * (data_sup_1[:, idx_nbe] / 12))#-        \n",
    "        overall_metric = calculate_metric_2(matrix_conf)\n",
    "    else:\n",
    "        optimisation_min = ['pessimiste']\n",
    "        if METRIC_2 in optimisation_min:\n",
    "            overall_metric = float('inf')\n",
    "        else:\n",
    "            overall_metric = -float('inf')\n",
    "        \"\"\"\n",
    "        global METRIC\n",
    "        METRIC = \"cs\"\n",
    "        data_all_lenght = len(data_inf) + len(data_sup)\n",
    "    \n",
    "        #compute overall metric value\n",
    "        metric_data_inf = (len(data_inf) / data_all_lenght) * calculate_metric(data_inf, idx_montant, idx_taux, idx_nbe)\n",
    "        metric_data_sup = (len(data_sup) / data_all_lenght) * calculate_metric(data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "        overall_metric = metric_data_inf + metric_data_sup\n",
    "        \"\"\"\n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def determine_best_split_update_2(data, potential_splits, idx_montant, idx_taux, idx_nbe):\n",
    "     \n",
    "    #print(potential_splits)\n",
    "    \n",
    "    #So let's implement parralel version of our super code\n",
    "    #Parallel(n_jobs=-1, require='sharedmem')(\n",
    "     #   delayed(func)(args)\n",
    "    #)\n",
    "    #global best_split_column, best_split_value, overall_metric_value\n",
    "    \n",
    "    #overall_metric_value = 300000000000000\n",
    "    optimisation_max = ['total', 'optimiste', 'reel']\n",
    "    optimisation_min = ['pessimiste']\n",
    "    if METRIC_2 in optimisation_min:\n",
    "        overall_metric_value = float('inf')\n",
    "    else:\n",
    "        overall_metric_value = -float('inf')\n",
    "    #with Parallel(n_jobs=-1, backend=\"threading\", require=\"sharedmem\", verbose=5) as parallel:\n",
    "      #  parallel(delayed(computing_best_column)(data, colum_index, value) for colum_index in potential_splits for value in potential_splits[colum_index]) \n",
    "    best_split_columns = 0\n",
    "    best_split_value = 0\n",
    "    for colum_index in potential_splits:\n",
    "        #print(\"current column: {}\".format(colum_index))\n",
    "        for value in potential_splits[colum_index]:\n",
    "            #print(\"current value: {}\".format(value))\n",
    "            data_inf, data_sup = split_data_2(data, colum_index, value)\n",
    "            #print(\"data_inf[:, -1] : \", data_inf[:, -1])\n",
    "            #print(\"data_sup[:, -1] : \", data_sup[:, -1])\n",
    "            #print(type(data_inf))\n",
    "            \n",
    "            if len(data_inf[:, -1]) != 0 and len(data_sup[:, -1]) == 0:\n",
    "                #print(\"data_sup[:, -1] : \", data_sup[:, -1])\n",
    "                bincount_inf = np.bincount(np.array(data_inf[:, -1], dtype=np.int64))\n",
    "                classe_maj_inf = bincount_inf.argmax()\n",
    "                if classe_maj_inf == 0:\n",
    "                    classe_maj_sup = 1\n",
    "                else:\n",
    "                    classe_maj_sup = 0\n",
    "            elif len(data_inf[:, -1]) == 0 and len(data_sup[:, -1]) != 0:\n",
    "                #print(\"data_inf[:, -1] : \", data_inf[:, -1])\n",
    "                bincount_sup = np.bincount(np.array(data_sup[:, -1], dtype=np.int64))\n",
    "                classe_maj_sup = bincount_sup.argmax()\n",
    "                if classe_maj_sup == 0:\n",
    "                    classe_maj_inf = 1\n",
    "                else:\n",
    "                    classe_maj_inf = 0\n",
    "            else:\n",
    "                #print(\"data_inf[:, -1] : \", data_inf[:, -1])\n",
    "                #print(\"data_sup[:, -1] : \", data_sup[:, -1])\n",
    "                bincount_inf = np.bincount(np.array(data_inf[:, -1], dtype=np.int64))\n",
    "                bincount_sup = np.bincount(np.array(data_sup[:, -1], dtype=np.int64))\n",
    "                classe_maj_inf = bincount_inf.argmax()\n",
    "                classe_maj_sup = bincount_sup.argmax()        \n",
    "        \n",
    "\n",
    "            #classe_maj_inf = 0\n",
    "            #classe_maj_sup = 1\n",
    "            current_overall = overall_metric_update_2(data_inf, data_sup, classe_maj_inf, classe_maj_sup, idx_montant, idx_taux, idx_nbe)\n",
    "            #print(current_overall)\n",
    "            #check if lower\n",
    "            \n",
    "            if METRIC_2 in optimisation_min:\n",
    "                if current_overall <= overall_metric_value:\n",
    "                    ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "                    overall_metric_value = current_overall\n",
    "                    best_split_columns = colum_index\n",
    "                    best_split_value = value\n",
    "            else:\n",
    "                if current_overall >= overall_metric_value:\n",
    "                    ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "                    overall_metric_value = current_overall\n",
    "                    best_split_columns = colum_index\n",
    "                    best_split_value = value\n",
    "\n",
    "    #print(best_split_value)\n",
    "    #Loop over all datas, calculate overall_entropy, and update if it's lower\n",
    "    \n",
    "    #print(\"Final Done !! bests: ({}, {}, {})\".format(best_split_columns, best_split_value, overall_metric_value))\n",
    "    return best_split_columns, best_split_value, overall_metric_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def determine_best_split_update_v1_2(data, potential_splits, idx_montant, idx_taux, idx_nbe):\n",
    "     \n",
    "    #print(potential_splits)\n",
    "    \n",
    "    #So let's implement parralel version of our super code\n",
    "    #Parallel(n_jobs=-1, require='sharedmem')(\n",
    "     #   delayed(func)(args)\n",
    "    #)\n",
    "    #global best_split_column, best_split_value, overall_metric_value\n",
    "    \n",
    "    #overall_metric_value = 300000000000000\n",
    "    optimisation_max = ['total', 'optimiste', 'reel']\n",
    "    optimisation_min = ['pessimiste']\n",
    "    if METRIC_2 in optimisation_min:\n",
    "        overall_metric_value = float('inf')\n",
    "    else:\n",
    "        overall_metric_value = -float('inf')\n",
    "    #with Parallel(n_jobs=-1, backend=\"threading\", require=\"sharedmem\", verbose=5) as parallel:\n",
    "      #  parallel(delayed(computing_best_column)(data, colum_index, value) for colum_index in potential_splits for value in potential_splits[colum_index]) \n",
    "    best_split_columns = 0\n",
    "    best_split_value = 0\n",
    "    for colum_index in potential_splits:\n",
    "        #print(\"current column: {}\".format(colum_index))\n",
    "        for value in potential_splits[colum_index]:\n",
    "            #print(\"current value: {}\".format(value))\n",
    "            data_inf, data_sup = split_data_2(data, colum_index, value)\n",
    "            #print(\"data_inf[:, -1] : \", data_inf[:, -1])\n",
    "            #print(\"data_sup[:, -1] : \", data_sup[:, -1])\n",
    "            #print(type(data_inf))\n",
    "            \n",
    "            if len(data_inf[:, -1]) != 0 and len(data_sup[:, -1]) == 0:\n",
    "                #print(\"data_sup[:, -1] : \", data_sup[:, -1])\n",
    "                bincount_inf = np.bincount(np.array(data_inf[:, -1], dtype=np.int64))\n",
    "                classe_maj_inf = bincount_inf.argmax()\n",
    "                if classe_maj_inf == 0:\n",
    "                    classe_maj_sup = 1\n",
    "                else:\n",
    "                    classe_maj_sup = 0\n",
    "            elif len(data_inf[:, -1]) == 0 and len(data_sup[:, -1]) != 0:\n",
    "                #print(\"data_inf[:, -1] : \", data_inf[:, -1])\n",
    "                bincount_sup = np.bincount(np.array(data_sup[:, -1], dtype=np.int64))\n",
    "                classe_maj_sup = bincount_sup.argmax()\n",
    "                if classe_maj_sup == 0:\n",
    "                    classe_maj_inf = 1\n",
    "                else:\n",
    "                    classe_maj_inf = 0\n",
    "            else:\n",
    "                #print(\"data_inf[:, -1] : \", data_inf[:, -1])\n",
    "                #print(\"data_sup[:, -1] : \", data_sup[:, -1])\n",
    "                bincount_inf = np.bincount(np.array(data_inf[:, -1], dtype=np.int64))\n",
    "                bincount_sup = np.bincount(np.array(data_sup[:, -1], dtype=np.int64))\n",
    "                classe_maj_inf = bincount_inf.argmax()\n",
    "                classe_maj_sup = bincount_sup.argmax()        \n",
    "        \n",
    "            \n",
    "            #if classe_maj_inf == classe_maj_sup:\n",
    "            classe_maj_inf = modified_classify_2(data_inf, idx_montant, idx_taux, idx_nbe)\n",
    "            classe_maj_inf = modified_classify_2(data_sup, idx_montant, idx_taux, idx_nbe)    \n",
    "            #classe_maj_inf = 0\n",
    "            #classe_maj_sup = 1\n",
    "            current_overall = overall_metric_update_2(data_inf, data_sup, classe_maj_inf, classe_maj_sup, idx_montant, idx_taux, idx_nbe)\n",
    "            #print(current_overall)\n",
    "            #check if lower\n",
    "            \n",
    "            if METRIC_2 in optimisation_min:\n",
    "                if current_overall <= overall_metric_value:\n",
    "                    ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "                    overall_metric_value = current_overall\n",
    "                    best_split_columns = colum_index\n",
    "                    best_split_value = value\n",
    "            else:\n",
    "                if current_overall >= overall_metric_value:\n",
    "                    ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "                    overall_metric_value = current_overall\n",
    "                    best_split_columns = colum_index\n",
    "                    best_split_value = value\n",
    "\n",
    "    #print(best_split_value)\n",
    "    #Loop over all datas, calculate overall_entropy, and update if it's lower\n",
    "    \n",
    "    #print(\"Final Done !! bests: ({}, {}, {})\".format(best_split_columns, best_split_value, overall_metric_value))\n",
    "    return best_split_columns, best_split_value, overall_metric_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#determine best split attribute and value\n",
    "def determine_best_split_2(data, potential_splits, idx_montant, idx_taux, idx_nbe):\n",
    "     \n",
    "    #print(potential_splits)\n",
    "    \n",
    "    #So let's implement parralel version of our super code\n",
    "    #Parallel(n_jobs=-1, require='sharedmem')(\n",
    "     #   delayed(func)(args)\n",
    "    #)\n",
    "    #global best_split_column, best_split_value, overall_metric_value\n",
    "    \n",
    "    #overall_metric_value = 300000000000000\n",
    "    optimisation_max = ['total', 'optimiste', 'reel']\n",
    "    optimisation_min = ['pessimiste']\n",
    "    if METRIC_2 in optimisation_min:\n",
    "        overall_metric_value = float('inf')\n",
    "    else:\n",
    "        overall_metric_value = -float('inf')\n",
    "    #with Parallel(n_jobs=-1, backend=\"threading\", require=\"sharedmem\", verbose=5) as parallel:\n",
    "      #  parallel(delayed(computing_best_column)(data, colum_index, value) for colum_index in potential_splits for value in potential_splits[colum_index]) \n",
    "    best_split_columns = 0\n",
    "    best_split_value = 0\n",
    "    for colum_index in potential_splits:\n",
    "        #print(\"current column: {}\".format(colum_index))\n",
    "        for value in potential_splits[colum_index]:\n",
    "            #print(\"current value: {}\".format(value))\n",
    "            data_inf, data_sup = split_data_2(data, colum_index, value)\n",
    "            #print(np.array(data_inf[:, -1], dtype=np.int64))\n",
    "            #print(type(data_inf))\n",
    "            if np.any(data_inf[:, -1]) != False and np.any(data_sup[:, -1]) == False:\n",
    "                bincount_inf = np.bincount(np.array(data_inf[:, -1], dtype=np.int64))\n",
    "                classe_maj_inf = bincount_inf.argmax()\n",
    "                if classe_maj_inf == 0:\n",
    "                    classe_maj_sup = 1\n",
    "                else:\n",
    "                    classe_maj_sup = 0\n",
    "            elif np.any(data_inf[:, -1]) == False and np.any(data_sup[:, -1]) != False:\n",
    "                bincount_sup = np.bincount(np.array(data_sup[:, -1], dtype=np.int64))\n",
    "                classe_maj_sup = bincount_sup.argmax()\n",
    "                if classe_maj_sup == 0:\n",
    "                    classe_maj_inf = 1\n",
    "                else:\n",
    "                    classe_maj_inf = 0\n",
    "            else:\n",
    "                #print(\"data_inf[:, -1] : \", data_inf[:, -1])\n",
    "                #print(\"data_sup[:, -1] : \", data_sup[:, -1])\n",
    "                bincount_inf = np.bincount(np.array(data_inf[:, -1], dtype=np.int64))\n",
    "                bincount_sup = np.bincount(np.array(data_sup[:, -1], dtype=np.int64))\n",
    "                classe_maj_inf = bincount_inf.argmax()\n",
    "                classe_maj_sup = bincount_sup.argmax()        \n",
    "                \n",
    "            if classe_maj_inf == classe_maj_sup:\n",
    "                if max(bincount_inf) > max(bincount_sup):\n",
    "                    if classe_maj_inf == 1:\n",
    "                        classe_maj_sup = 0\n",
    "                    else:\n",
    "                        classe_maj_sup = 1\n",
    "                else:\n",
    "                    if classe_maj_sup == 1:\n",
    "                        classe_maj_inf = 0\n",
    "                    else:\n",
    "                        classe_maj_inf = 1\n",
    "            #classe_maj_inf = 0\n",
    "            #classe_maj_sup = 1\n",
    "            current_overall = overall_metric_2(data_inf, data_sup, classe_maj_inf, classe_maj_sup, idx_montant, idx_taux, idx_nbe)\n",
    "            #print(current_overall)\n",
    "            #check if lower\n",
    "            \n",
    "            if METRIC_2 in optimisation_min:\n",
    "                if current_overall <= overall_metric_value:\n",
    "                    ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "                    overall_metric_value = current_overall\n",
    "                    best_split_columns = colum_index\n",
    "                    best_split_value = value\n",
    "            else:\n",
    "                if current_overall >= overall_metric_value:\n",
    "                    ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "                    overall_metric_value = current_overall\n",
    "                    best_split_columns = colum_index\n",
    "                    best_split_value = value\n",
    "\n",
    "    #print(best_split_value)\n",
    "    #Loop over all datas, calculate overall_entropy, and update if it's lower\n",
    "    \n",
    "    #print(\"Final Done !! bests: ({}, {}, {})\".format(best_split_columns, best_split_value, overall_metric_value))\n",
    "    return best_split_columns, best_split_value, overall_metric_value\n",
    "\n",
    "#building decision Tree\n",
    "def decision_tree_2(df, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter=0, min_samples=5, max_depth=5, metric=\"entropy\"):\n",
    "    \n",
    "    if counter == 0:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            data = df.values\n",
    "        else: \n",
    "            data = df\n",
    "        global COLUMNS_NAMES_2, FEATURE_TYPES_2, METRIC_2\n",
    "        COLUMNS_NAMES_2 = df.columns[:-1]\n",
    "        FEATURE_TYPES_2 = determine_feature_types(df)\n",
    "        METRIC_2 = metric\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    #base case\n",
    "    potential_splits = get_splits_2(data, index_feature_not_selected, idx_montant)\n",
    "    #print(potential_splits)\n",
    "    if check_purity_2(data) or (len(data) < min_samples) or (counter == max_depth) or potential_splits == {}:\n",
    "        classification = modified_classify_2(data, idx_montant, idx_taux, idx_nbe)\n",
    "        return classification\n",
    "    \n",
    "    else:\n",
    "        counter +=1\n",
    "        #computations for right and left part \n",
    "        best_split_column, best_split_value, overall_metric_value = determine_best_split_update_2(data, potential_splits, idx_montant, idx_taux, idx_nbe)\n",
    "        \n",
    "        #We must change data_inf & data_sup order later\n",
    "        data_inf, data_sup = split_data_2(data, best_split_column, best_split_value)\n",
    "        \n",
    "        # Creating subTree\n",
    "        feature_type = FEATURE_TYPES_2[best_split_column]    \n",
    "        if feature_type == \"Continous\":\n",
    "            question = \"{} <= {}\".format(COLUMNS_NAMES_2[best_split_column], best_split_value)\n",
    "        else:\n",
    "            question = \"{} == {}\".format(COLUMNS_NAMES_2[best_split_column], best_split_value)\n",
    "        #Adding labels\n",
    "        labels = \" \" + str(len(data_inf) + len(data_sup)) + \" \" + str(overall_metric_value)\n",
    "        question += labels\n",
    "        sub_tree = {question: []}\n",
    "        ###print(question)            \n",
    "        #index_feature_not_selected.append(best_split_column)\n",
    "        #left and right\n",
    "        yes_answer = decision_tree_2(data_inf, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter, min_samples, max_depth, metric=METRIC_2)\n",
    "        no_answer = decision_tree_2(data_sup, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter, min_samples, max_depth, metric=METRIC_2)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            ###print(yes_answer)\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            #Append left and right part\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e6ec96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data purity\n",
    "def check_purity_3(data):\n",
    "    #print(\"check purity : \", len(np.unique(data[:,-1])) == 1)\n",
    "    #Return purity value regarding to the number of unique classes\n",
    "    return  (False,True)[len(np.unique(data[:,-1])) == 1]\n",
    "    \n",
    "#Normal classification using majority\n",
    "def classify_3(data):\n",
    "    #get all classes & count occurences\n",
    "    label = data[:,-1]\n",
    "    uniques_classes, counts = np.unique(data[:,-1], return_counts = True)\n",
    "    \n",
    "    #get index of most common class\n",
    "    index = counts.argmax()\n",
    "    \n",
    "    #return the most common class\n",
    "    return uniques_classes[index]\n",
    "\n",
    "# Modified Classification using proposed approach\n",
    "def modified_classify_3(data, idx_montant, idx_taux, idx_nbe):\n",
    "    #initializing\n",
    "    P  = 0\n",
    "    M = 0\n",
    "    n_row , _ = data.shape\n",
    "    index_montant = idx_montant #13\n",
    "    index_taux = idx_taux #2\n",
    "    index_nbe = idx_nbe #4\n",
    "    for line in range(n_row):\n",
    "        if data[line,-1] == 0:\n",
    "            P += data[line,index_montant]\n",
    "        else:\n",
    "            M += (data[line, index_taux]/100) * data[line,index_montant] * data[line,index_nbe]/12\n",
    "        #print(\"({} , {})\".format(data[line,index_montant], data[line, index_taux]))\n",
    "    \n",
    "    #print(\"({}, {})\".format(P, M))\n",
    "    \n",
    "    return (0, 1)[M > P]\n",
    "        \n",
    "\n",
    "#Calculate all potential splits\n",
    "def get_splits_3(data, index_feature_not_selected, col_montant):\n",
    "    \n",
    "    #initialize our dict of potential splits\n",
    "    splits = {}\n",
    "    \n",
    "    #initialize all attribute potential splits list\n",
    "    _, n_cols = data.shape\n",
    "    #for col in range(n_cols - 1):\n",
    "    #    if col in index_feature_not_selected or col == col_montant:\n",
    "    #        continue\n",
    "    #    splits[col] = list()\n",
    "    \n",
    "    # Compute all attributes potential splits\n",
    "    for col in range(n_cols - 1):\n",
    "        #get unique datas\n",
    "        #print(\"Current col: {}\".format(col))\n",
    "        if col in index_feature_not_selected or col == col_montant:\n",
    "            continue\n",
    "\n",
    "        values = np.unique(data[:, col])\n",
    "        #print(\"values :\", values)\n",
    "        #populate our dict\n",
    "        feature_type = FEATURE_TYPES[col]\n",
    "        if feature_type == \"Continous\":\n",
    "            for index in range(1, len(values)):\n",
    "                if not col in splits:\n",
    "                    splits[col] = list()\n",
    "                current_value = values[index]\n",
    "                #print(current_value)\n",
    "                previous_value = values[index - 1]\n",
    "                potential_split = np.mean([current_value, previous_value])\n",
    "                splits[col].append(potential_split)\n",
    "        else:\n",
    "            splits[col] = values\n",
    "    #print(\"splits : \", splits)\n",
    "    return splits\n",
    "\n",
    "#Spliting data\n",
    "def split_data_3(data, feature_col, value):\n",
    "    \n",
    "    feature_type = FEATURE_TYPES[feature_col]\n",
    "    \n",
    "    #define all masks\n",
    "    \n",
    "    if feature_type == \"Continous\":\n",
    "        mask_inf = data[:, feature_col] <= value\n",
    "        mask_sup = data[:, feature_col] > value\n",
    "    else:\n",
    "        mask_inf = data[:, feature_col] == value\n",
    "        mask_sup = data[:, feature_col] != value\n",
    "    \n",
    "    #data spliting\n",
    "    data_inf = data[mask_inf]\n",
    "    data_sup = data[mask_sup]\n",
    "    \n",
    "    return data_inf, data_sup\n",
    "\n",
    "\n",
    "#Calculate chosen metric\n",
    "def calculate_metric_3(data, classe_pred, idx_montant, idx_taux, idx_nbe):\n",
    "     #get classes\n",
    "    label_class = data[:, -1]\n",
    "    #get counts for each class\n",
    "    _, counts = np.unique(label_class, return_counts=True)\n",
    "    \n",
    "    probabilities = counts / counts.sum()\n",
    "    \n",
    "    #computing metric value depending on the user choice\n",
    "    if METRIC == \"entropy\":\n",
    "        probabilities = counts / counts.sum()\n",
    "        computed_metric = sum(probabilities * -np.log2(probabilities))\n",
    "    elif METRIC == \"gini\":\n",
    "        probabilities **=2\n",
    "        computed_metric = 1- sum(probabilities)\n",
    "    elif METRIC == \"cs\":\n",
    "        #print(\"cs\")\n",
    "        P  = 0\n",
    "        M = 0\n",
    "        n_row , _ = data.shape\n",
    "        index_montant = idx_montant #13\n",
    "        index_taux = idx_taux #12\n",
    "        index_nbe = idx_nbe #4\n",
    "        i = 0\n",
    "        for line in range(n_row):\n",
    "            if data[line,-1] == 0 and classe_pred == 1:\n",
    "                P += data[line,index_montant]\n",
    "                i += 1\n",
    "            elif data[line,-1] == 1 and classe_pred == 0:\n",
    "                P += (data[line, index_taux]/100) * data[line,index_montant] * data[line,index_nbe]/12\n",
    "                i += 1\n",
    "        #computed_metric = (i/counts.sum())*P\n",
    "        computed_metric = P\n",
    "    \n",
    "    return computed_metric\n",
    "\n",
    "# Overall metric value\n",
    "def overall_metric_3(data_inf, data_sup, idx_montant, idx_taux, idx_nbe):\n",
    "    data_all_lenght = len(data_inf) + len(data_sup)\n",
    "    if len(data_inf[:, -1]) != 0 and len(data_sup[:, -1]) == 0:\n",
    "        #print(\"data_sup[:, -1] : \", data_sup[:, -1])\n",
    "        bincount_inf = np.bincount(np.array(data_inf[:, -1], dtype=np.int64))\n",
    "        classe_maj_inf = bincount_inf.argmax()\n",
    "        if classe_maj_inf == 0:\n",
    "            classe_maj_sup = 1\n",
    "        else:\n",
    "            classe_maj_sup = 0\n",
    "    elif len(data_inf[:, -1]) == 0 and len(data_sup[:, -1]) != 0:\n",
    "        #print(\"data_inf[:, -1] : \", data_inf[:, -1])\n",
    "        bincount_sup = np.bincount(np.array(data_sup[:, -1], dtype=np.int64))\n",
    "        classe_maj_sup = bincount_sup.argmax()\n",
    "        if classe_maj_sup == 0:\n",
    "            classe_maj_inf = 1\n",
    "        else:\n",
    "            classe_maj_inf = 0\n",
    "    else:\n",
    "        #print(\"data_inf[:, -1] : \", data_inf[:, -1])\n",
    "        #print(\"data_sup[:, -1] : \", data_sup[:, -1])\n",
    "        bincount_inf = np.bincount(np.array(data_inf[:, -1], dtype=np.int64))\n",
    "        bincount_sup = np.bincount(np.array(data_sup[:, -1], dtype=np.int64))\n",
    "        classe_maj_inf = bincount_inf.argmax()\n",
    "        classe_maj_sup = bincount_sup.argmax()        \n",
    "    \n",
    "    #compute overall metric value\n",
    "    metric_data_inf = calculate_metric_3(data_inf, classe_maj_inf, idx_montant, idx_taux, idx_nbe)\n",
    "    metric_data_sup = calculate_metric_3(data_sup, classe_maj_sup, idx_montant, idx_taux, idx_nbe)\n",
    "    \n",
    "    overall_metric= metric_data_inf + metric_data_sup\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "#Modified metric: Here the aim is to compute the total lost that we'll have\n",
    "def modified_metric_3(data, idx_montant, idx_taux, idx_nbe):\n",
    "    #initializing\n",
    "    P  = 0\n",
    "    M = 0\n",
    "    n_row , _ = data.shape\n",
    "    index_montant = idx_montant #13\n",
    "    index_taux = idx_taux #12\n",
    "    index_nbe = idx_nbe #4\n",
    "    for line in range(n_row):\n",
    "        if data[line,-1] == 0:\n",
    "            P += data[line,index_montant]\n",
    "        #else:\n",
    "            #M += (data[line, index_taux]/100) * data[line,index_montant] \n",
    "    #print(P)\n",
    "    return P\n",
    "\n",
    "#Compute our overall modified metric\n",
    "def overall_modified_metric_3(data_inf, data_sup, idx_montant, idx_taux, idx_nbe):\n",
    "    #get number of datas\n",
    "    data_all_lenght = len(data_inf) + len(data_sup)\n",
    "    \n",
    "    #compute overall metric value\n",
    "    metric_data_inf = (len(data_inf) / data_all_lenght)*modified_metric_3(data_inf, idx_montant, idx_taux, idx_nbe)\n",
    "    metric_data_sup = (len(data_sup) / data_all_lenght)*modified_metric_3(data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "    overall_metric= metric_data_inf + metric_data_sup\n",
    "    #print(\"({}, {})\".format(metric_data_inf, metric_data_sup))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "#parralelized function\n",
    "def computing_best_column_3(data, colum_index, value, idx_montant, idx_taux, idx_nbe):\n",
    "    \n",
    "    global best_split_column, best_split_value, overall_metric_value\n",
    "    \n",
    "    #print(\"current column: {}\".format(colum_index))\n",
    "    data_inf, data_sup = split_data_3(data, colum_index, value)\n",
    "    current_overall = overall_modified_metric_3(data_inf, data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "            #print(current_overall)\n",
    "            #check if lower\n",
    "    if current_overall <= overall_metric_value:\n",
    "        ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "        overall_metric_value = current_overall\n",
    "        best_split_column = colum_index\n",
    "        best_split_value = value\n",
    "        #print(\"Done !! bests: ({}, {}, {})\".format(best_split_column, best_split_value, overall_metric_value))\n",
    "\n",
    "#determine best split attribute and value\n",
    "def determine_best_split_3(data, potential_splits, idx_montant, idx_taux, idx_nbe):\n",
    "     \n",
    "    #print(potential_splits)\n",
    "    \n",
    "    #So let's implement parralel version of our super code\n",
    "    #Parallel(n_jobs=-1, require='sharedmem')(\n",
    "     #   delayed(func)(args)\n",
    "    #)\n",
    "    #global best_split_column, best_split_value, overall_metric_value\n",
    "    \n",
    "    #overall_metric_value = 300000000000000\n",
    "    overall_metric_value = float('inf')\n",
    "    #with Parallel(n_jobs=-1, backend=\"threading\", require=\"sharedmem\", verbose=5) as parallel:\n",
    "      #  parallel(delayed(computing_best_column)(data, colum_index, value) for colum_index in potential_splits for value in potential_splits[colum_index]) \n",
    "    best_split_columns = 0\n",
    "    best_split_value = 0\n",
    "    for colum_index in potential_splits:\n",
    "        #print(\"current column: {}\".format(colum_index))\n",
    "        for value in potential_splits[colum_index]:\n",
    "            #print(\"current value: {}\".format(value))\n",
    "            data_inf, data_sup = split_data_3(data, colum_index, value)\n",
    "            current_overall = overall_metric_3(data_inf, data_sup, idx_montant, idx_taux, idx_nbe)\n",
    "            #print(current_overall)\n",
    "            #check if lower\n",
    "            if current_overall <= overall_metric_value:\n",
    "                ####print(\"cur,met, val, col, : ({}, {},{},{})\".format(current_overall, overall_metric_value, colum_index, value))\n",
    "                overall_metric_value = current_overall\n",
    "                best_split_columns = colum_index\n",
    "                best_split_value = value\n",
    "    #print(best_split_value)\n",
    "    #Loop over all datas, calculate overall_entropy, and update if it's lower\n",
    "    \n",
    "    #print(\"Final Done !! bests: ({}, {}, {})\".format(best_split_columns, best_split_value, overall_metric_value))\n",
    "    return best_split_columns, best_split_value, overall_metric_value\n",
    "\n",
    "#building decision Tree\n",
    "def decision_tree_3(df, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter=0, min_samples=5, max_depth=5, metric=\"entropy\"):\n",
    "    \n",
    "    if counter == 0:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            data = df.values\n",
    "        else: \n",
    "            data = df\n",
    "        global COLUMNS_NAMES, FEATURE_TYPES, METRIC\n",
    "        COLUMNS_NAMES = df.columns[:-1]\n",
    "        FEATURE_TYPES = determine_feature_types(df)\n",
    "        METRIC = metric\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    #base case\n",
    "    potential_splits = get_splits(data, index_feature_not_selected, idx_montant)\n",
    "    #print(potential_splits)\n",
    "    if check_purity(data) or (len(data) < min_samples) or (counter == max_depth) or potential_splits == {}:\n",
    "        classification = modified_classify_3(data, idx_montant, idx_taux, idx_nbe)\n",
    "        return classification\n",
    "    \n",
    "    else:\n",
    "        counter +=1\n",
    "        #computations for right and left part \n",
    "        best_split_column, best_split_value, overall_metric_value = determine_best_split_3(data, potential_splits, idx_montant, idx_taux, idx_nbe)\n",
    "        \n",
    "        #We must change data_inf & data_sup order later\n",
    "        data_inf, data_sup = split_data_3(data, best_split_column, best_split_value)\n",
    "        \n",
    "        # Creating subTree\n",
    "        feature_type = FEATURE_TYPES[best_split_column]    \n",
    "        if feature_type == \"Continous\":\n",
    "            question = \"{} <= {}\".format(COLUMNS_NAMES[best_split_column], best_split_value)\n",
    "        else:\n",
    "            question = \"{} == {}\".format(COLUMNS_NAMES[best_split_column], best_split_value)\n",
    "        #Adding labels\n",
    "        labels = \" \" + str(len(data_inf) + len(data_sup)) + \" \" + str(overall_metric_value)\n",
    "        question += labels\n",
    "        sub_tree = {question: []}\n",
    "        ###print(question)            \n",
    "        #index_feature_not_selected.append(best_split_column)\n",
    "        #left and right\n",
    "        yes_answer = decision_tree_3(data_inf, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter, min_samples, max_depth, metric=METRIC)\n",
    "        no_answer = decision_tree_3(data_sup, index_feature_not_selected, idx_montant, idx_taux, idx_nbe, counter, min_samples, max_depth, metric=METRIC)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            ###print(yes_answer)\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            #Append left and right part\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526e97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe49a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_presence(classe_name, x):\n",
    "    val = False\n",
    "    for i in classe_name:\n",
    "        if i in x:\n",
    "            val = True\n",
    "    return val\n",
    "\n",
    "def processing_feature_selection_AR(df, dfv, sep, val_class, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "\n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[classe].unique())\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    vector = dict()\n",
    "    for i in df.columns.values:\n",
    "        vector[i] = []\n",
    "    del vector[classe]\n",
    "\n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        vector[item].append(rules['confidence'][i])\n",
    "    print(vector)\n",
    "    print(\"\\n\")\n",
    "    for key, value in vector.items():\n",
    "        if vector[key] == []:\n",
    "            vector[key] = 0.0\n",
    "        else:\n",
    "            vector[key] = np.max(value, axis=0)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_base(df, dfv, sep, val_class, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "\n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[classe].unique())\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    vector = dict()\n",
    "    \n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        if not item in vector:\n",
    "            vector[item] = []\n",
    "        vector[item].append(rules['confidence'][i])\n",
    "    \n",
    "    for key, value in vector.items():\n",
    "        vector[key] = np.max(value, axis=0)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_merge_normal_inverse(df, dfv, sep, val_class, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "\n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = df[classe].unique()\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules1 = rules\n",
    "    rules2 = rules\n",
    "    \n",
    "    rules1['select'] = rules1['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules1 = rules1[ rules1['select'] == True]\n",
    "    rules1['select'] = rules1['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules1 = rules1[ rules1['select'] == True]\n",
    "    \n",
    "    rules1['length_antecedents'] = rules1['antecedents'].apply(lambda x: len(x))\n",
    "    rules1['length_consequents'] = rules1['consequents'].apply(lambda x: len(x))\n",
    "    rules1 = rules1[ (rules1['length_antecedents'] == 1) & (rules1['length_consequents'] == 1)]\n",
    "    \n",
    "    \n",
    "    rules2['select'] = rules2['antecedents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules2 = rules2[ rules2['select'] == True]\n",
    "    rules2['select'] = rules2['consequents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules2 = rules2[ rules2['select'] == True]\n",
    "    \n",
    "    rules2['length_antecedents'] = rules2['antecedents'].apply(lambda x: len(x))\n",
    "    rules2['length_consequents'] = rules2['consequents'].apply(lambda x: len(x))\n",
    "    rules2 = rules2[ (rules2['length_antecedents'] == 1) & (rules2['length_consequents'] == 1)]                   \n",
    "    \n",
    "    vector1 = dict()\n",
    "    vector2 = dict()\n",
    "    for i in df.columns.values:\n",
    "        vector1[i] = []\n",
    "        vector2[i] = []\n",
    "    del vector1[classe]\n",
    "    del vector2[classe]\n",
    "    \n",
    "    for i in rules1.index:\n",
    "        item = list(rules1['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        vector1[item].append(rules1['confidence'][i])\n",
    "    \n",
    "    for i in rules2.index:    \n",
    "        item = list(rules2['consequents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        vector2[item].append(rules2['confidence'][i])\n",
    "        \n",
    "        #print(item)\n",
    "    for key, value in vector1.items():\n",
    "        if vector1[key] == []:\n",
    "            vector1[key] = 0.0\n",
    "        else:\n",
    "            vector1[key] = np.max(value, axis=0)\n",
    "    \n",
    "    for key, value in vector2.items():\n",
    "        if vector2[key] == []:\n",
    "            vector2[key] = 0.0\n",
    "        else:\n",
    "            vector2[key] = np.max(value, axis=0)\n",
    "\n",
    "    for key, value in vector1.items():\n",
    "        vector1[key] = vector1[key] + vector2[key]\n",
    "\n",
    "            \n",
    "    sorted_vector = sorted(vector1.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_inverse(df, dfv, sep, val_class, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "\n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = df[classe].unique()\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    \n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    \n",
    "    vector = dict()\n",
    "    for i in df.columns.values:\n",
    "        vector[i] = []\n",
    "    del vector[classe]\n",
    "\n",
    "    for i in rules.index:\n",
    "        item = list(rules['consequents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        vector[item].append(rules['confidence'][i])\n",
    "        #print(item)\n",
    "    for key, value in vector.items():\n",
    "        if vector[key] == []:\n",
    "            vector[key] = 0.0\n",
    "        else:\n",
    "            vector[key] = np.max(value, axis=0)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_oriented_classe(df, dfv, sep, val_class, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "\n",
    "    #classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[val_class].unique())\n",
    "    for i in range(len(unique_classe)):\n",
    "        unique_classe[i] = str(unique_classe[i]) \n",
    "    \n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(val_class + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    \n",
    "    columns = list(set(df.columns)-set([val_class]))\n",
    "\n",
    "    bloc = dict()\n",
    "    for i in unique_classe:\n",
    "        bloc[i] = dict()\n",
    "    \n",
    "    for i in unique_classe:\n",
    "        for j in columns:\n",
    "            bloc[i][j] = []\n",
    "    #print(bloc)    \n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        classe = list(rules['consequents'][i])[0]\n",
    "        classe = classe.split(sep)[1]\n",
    "        bloc[classe][item].append(rules['confidence'][i])\n",
    "    \n",
    "    #print(rules)\n",
    "    for classe in unique_classe:\n",
    "        for key, value in bloc[classe].items():\n",
    "            if bloc[classe][key] == []:\n",
    "                bloc[classe][key] = 0.0\n",
    "            else:\n",
    "                bloc[classe][key] = np.max(value, axis=0)\n",
    "    \n",
    "    \n",
    "    vector = dict()    \n",
    "    for i in columns:\n",
    "        vector[i] = 0.0\n",
    "        \n",
    "    for i in columns:\n",
    "        ls = []\n",
    "        for j in unique_classe:\n",
    "            ls.append(bloc[j][i])\n",
    "        #ls_norm = 1 / (1 + np.exp(-np.array(ls)))\n",
    "        ls_norm = expit(np.array(ls))\n",
    "        vector[i] = gini_ev(ls_norm)\n",
    "        #vector[i] = vector[i] + bloc[j][i]\n",
    "    \n",
    "    #for i in columns:\n",
    "    #    if vector[i] == 0.0:\n",
    "    #        vector[i] = 1.0\n",
    "        \n",
    "    #sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    \n",
    "    return sorted_vector\n",
    "def gini_ev(ls):\n",
    "    s = 0.0\n",
    "    for i in range(len(ls)):\n",
    "        s = s + ls[i]**2\n",
    "    return 1-s\n",
    "\n",
    "def processing_feature_selection_AR_Inverse_oriented_classe(df, dfv, sep, val_class, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "\n",
    "    #classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[val_class].unique())\n",
    "    for i in range(len(unique_classe)):\n",
    "        unique_classe[i] = str(unique_classe[i]) \n",
    "    \n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(val_class + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    \n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    \n",
    "    columns = list(set(df.columns)-set([val_class]))\n",
    "\n",
    "    bloc = dict()\n",
    "    for i in unique_classe:\n",
    "        bloc[i] = dict()\n",
    "\n",
    "    for i in unique_classe:\n",
    "        for j in columns:\n",
    "            bloc[i][j] = []\n",
    "        \n",
    "    for i in rules.index:\n",
    "        item = list(rules['consequents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        classe = list(rules['antecedents'][i])[0]\n",
    "        classe = classe.split(sep)[1]\n",
    "        bloc[classe][item].append(rules['confidence'][i])\n",
    "    \n",
    "    print(bloc)\n",
    "    print(\"\\n\")\n",
    "    for classe in unique_classe:\n",
    "        for key, value in bloc[classe].items():\n",
    "            if bloc[classe][key] == []:\n",
    "                bloc[classe][key] = 0.0\n",
    "            else:\n",
    "                bloc[classe][key] = np.max(value, axis=0)\n",
    "    \n",
    "    \n",
    "    vector = dict()    \n",
    "    for i in columns:\n",
    "        vector[i] = 0.0\n",
    "        \n",
    "    for i in columns:\n",
    "        ls = []\n",
    "        for j in unique_classe:\n",
    "            ls.append(bloc[j][i])\n",
    "        #ls_norm = 1 / (1 + np.exp(-np.array(ls)))\n",
    "        ls_norm = expit(np.array(ls))\n",
    "        vector[i] = gini_ev(ls_norm)\n",
    "        #vector[i] = vector[i] + bloc[j][i]\n",
    "    \n",
    "    #for i in columns:\n",
    "    #    if vector[i] == 0.0:\n",
    "    #        vector[i] = 1.0\n",
    "        \n",
    "    #sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    print(bloc)\n",
    "    print(\"\\n\")\n",
    "    return sorted_vector\n",
    "            \n",
    "def apply_loss_rules(rules, data, sep, name_montant, name_taux, name_duree, name_classe):\n",
    "    rules['confidence_loss'] = rules['confidence']\n",
    "    for i in rules.index:\n",
    "        datas = data.copy()\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item_a = item.split(sep)[0]\n",
    "        item_b = item.split(sep)[1]\n",
    "        datas['select'] = datas[item_a].apply(lambda x: str(x) == item_b)\n",
    "        datas = datas[datas['select'] == True]\n",
    "        \n",
    "        #total_loss = 0.0\n",
    "        #for j in datas.index:\n",
    "        #    if datas[name_classe][j] == 0:\n",
    "                 #print(\"tchuente 11\")\n",
    "        #        total_loss += datas[name_montant][j]\n",
    "        #    else:\n",
    "                #print(\"tchuente 12\")\n",
    "        #        total_loss += datas[name_montant][j] * (datas[name_taux][j]/100) * datas[name_duree][j]/12\n",
    "        \n",
    "        item = list(rules['consequents'][i])[0]\n",
    "        item_a = item.split(sep)[0]\n",
    "        item_b = item.split(sep)[1]\n",
    "        datas['select'] = datas[item_a].apply(lambda x: str(x) == item_b)\n",
    "        datas = datas[datas['select'] == True]\n",
    "        \n",
    "        #print(rules)\n",
    "\n",
    "        if item_b == '0':\n",
    "            #print(\"tchuente 1\")\n",
    "            loss = datas[name_montant].sum()\n",
    "        else:\n",
    "            #print(\"tchuente 2\")\n",
    "            df_no_win = datas[[name_montant, name_taux, name_duree]]\n",
    "            df_no_win[name_taux] /= 100\n",
    "            df_no_win[\"NoWin\"] = df_no_win[name_montant] * df_no_win[name_taux] * df_no_win[name_duree]/12\n",
    "            loss = df_no_win.NoWin.sum()\n",
    "\n",
    "        rules['confidence_loss'][i] = rules['confidence'][i]*loss\n",
    "        #rules['confidence_loss'][i] = loss\n",
    "        \n",
    "    return rules\n",
    "        \n",
    "        \n",
    "        \n",
    "def processing_feature_selection_AR_Sensitive_Loss(df, dfv, sep, val_class, name_montant, name_taux, name_duree, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "    \n",
    "    \n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[classe].unique())\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    \n",
    "    vector = dict()\n",
    "    columns = list(df.columns.values)\n",
    "    for i in columns:\n",
    "        if i == name_montant:\n",
    "            continue\n",
    "        vector[i] = []\n",
    "        \n",
    "    del vector[classe]\n",
    "    rules = apply_loss_rules(rules, df.copy(deep=True), sep, name_montant, name_taux, name_duree, val_class)\n",
    "\n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        if item == name_montant:\n",
    "            continue\n",
    "        vector[item].append(rules['confidence_loss'][i])\n",
    "    \n",
    "    print(vector)\n",
    "    print(\"\\n\")\n",
    "    for key, value in vector.items():\n",
    "        if vector[key] == []:\n",
    "            vector[key] = 0.0\n",
    "        else:\n",
    "            vector[key] = np.max(value, axis=0)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_Sensitive_Loss_(df, dfv, sep, val_class, name_montant, name_taux, name_duree, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "    \n",
    "    \n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[classe].unique())\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    \n",
    "    vector = dict()\n",
    "    columns = list(df.columns.values)\n",
    "    for i in columns:\n",
    "        if i == name_montant:\n",
    "            continue\n",
    "        vector[i] = []\n",
    "        \n",
    "    del vector[classe]\n",
    "    rules = apply_loss_rules(rules, df.copy(deep=True), sep, name_montant, name_taux, name_duree, val_class)\n",
    "\n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        if item == name_montant:\n",
    "            continue\n",
    "        vector[item].append(rules['confidence_loss'][i])\n",
    "    \n",
    "    print(vector)\n",
    "    print(\"\\n\")\n",
    "    for key, value in vector.items():\n",
    "        if vector[key] == []:\n",
    "            vector[key] = 0.0\n",
    "        else:\n",
    "            vector[key] = np.max(value, axis=0)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_base_Sensitive_Loss_(df, dfv, sep, val_class, name_montant, name_taux, name_duree, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "    \n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[classe].unique())\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    \n",
    "    vector = dict()\n",
    "    rules = apply_loss_rules(rules, df.copy(deep=True), sep, name_montant, name_taux, name_duree, val_class)\n",
    "\n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        if item == name_montant:\n",
    "            continue\n",
    "        if not item in vector:\n",
    "            vector[item] = []\n",
    "        vector[item].append(rules['confidence_loss'][i])\n",
    "    \n",
    "    for key, value in vector.items():\n",
    "        vector[key] = np.max(value, axis=0)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=False)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_base(df, dfv, sep, val_class, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "\n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[classe].unique())\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    vector = dict()\n",
    "    \n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        if not item in vector:\n",
    "            vector[item] = []\n",
    "        vector[item].append(rules['confidence'][i])\n",
    "    \n",
    "    for key, value in vector.items():\n",
    "        vector[key] = np.max(value, axis=0)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_base_Loss_(df, dfv, sep, val_class, name_montant, name_taux, name_duree, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min)\n",
    "    \n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[classe].unique())\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    \n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)]                   \n",
    "    \n",
    "    vector = dict()\n",
    "    rules = apply_loss_rules(rules, df.copy(deep=True), sep, name_montant, name_taux, name_duree, val_class)\n",
    "\n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        if item == name_montant:\n",
    "            continue\n",
    "        if not item in vector:\n",
    "            vector[item] = []\n",
    "        vector[item].append(rules['confidence_loss'][i])\n",
    "    \n",
    "    #for key, value in vector.items():\n",
    "    #    vector[key] = np.max(value, axis=0)\n",
    "    #sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=False)\n",
    "    \n",
    "    train, test = train_test_split_(df, 0.3)\n",
    "    index_feature_not_selected = []\n",
    "    idx_montant = df.columns.get_loc(name_montant)\n",
    "    idx_taux = df.columns.get_loc(name_taux)\n",
    "    idx_duree = df.columns.get_loc(name_duree)\n",
    "    \n",
    "    #random = 10\n",
    "    cricterior = 'cs'\n",
    "    set_feature = dict()\n",
    "    columns = df.columns.tolist()\n",
    "    len_columns = len(columns)\n",
    "    columns = list(set(columns) - set([val_class]))\n",
    "    #X_train, X_test, y_train, y_test, columns_extract_all = preprocessing_dataset_(df, [val_class], sep, val_class, random)\n",
    "    for col in columns:\n",
    "        if not col in vector:       \n",
    "            #X_train_selected, X_test_selected, columns_extract = selected_dataset_(columns_extract_all, [col], sep, X_train, X_test)\n",
    "            #means_scores, _, _, _ = model_evaluation_SFS_(X_train_selected, X_test_selected, y_train, y_test, columns_extract, columns, sep, cricterior)\n",
    "            #set_feature[col] = means_scores\n",
    "            \n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([df.columns.get_loc(col)]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([df.columns.get_loc(val_class)]))\n",
    "        \n",
    "            my_tree = decision_tree(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            accuracy, df_p = my_accuracy(test, my_tree, val_class)\n",
    "            _, means_scores = compute_metrics(df_p, val_class, name_montant, name_taux, name_duree)\n",
    "            set_feature[col] = means_scores\n",
    "            \n",
    "    for key, value in vector.items():\n",
    "        vector[key] = np.max(value, axis=0)\n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=False)\n",
    "    set_feature = sorted(set_feature.items(), key=lambda x:x[1], reverse=False)\n",
    "    print(\"sorted_vector : \", sorted_vector)\n",
    "    print(\"set_feature : \", set_feature)\n",
    "    for ele in set_feature:\n",
    "        sorted_vector.append(ele)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_base_Multi_Loss(df, dfv, cricterior, alpha, sep, val_class, name_montant, name_taux, name_duree, support_min_loss=0.07, metric_v=\"confidence\", threshold_min_loss=0.4, random=10):\n",
    "    #dict_loss = give_dict_loss(df, name_montant)\n",
    "    #print(\"dict_loss : \", dict_loss)\n",
    "    #frequent_items_loss = apriori_loss_sensitive(dfv.astype('bool'), dict_loss, min_support_loss=support_min_loss)\n",
    "    #print(\"frequent_items_loss : \", frequent_items_loss)\n",
    "    #rules = association_rules_(frequent_items_loss, metric_v, threshold_min_loss)\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min_loss, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min_loss)\n",
    "    \n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[classe].unique())\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    \n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)] \n",
    "    #print(rules)\n",
    "    \n",
    "    vector = dict()\n",
    "    rules = apply_loss_rules(rules, df.copy(deep=True), sep, name_montant, name_taux, name_duree, val_class)\n",
    "\n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        if item == name_montant:\n",
    "            continue\n",
    "        if not item in vector:\n",
    "            vector[item] = []\n",
    "        #vector[item].append(rules['confidence_loss'][i])\n",
    "        vector[item].append(rules['confidence_loss'][i])\n",
    "    \n",
    "    dataset_y = df[val_class]\n",
    "    dataset_x = df.drop([val_class], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random)\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    test = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    index_feature_not_selected = []\n",
    "    idx_montant = df.columns.get_loc(name_montant)\n",
    "    idx_taux = df.columns.get_loc(name_taux)\n",
    "    idx_duree = df.columns.get_loc(name_duree)\n",
    "    \n",
    "    #random = 10\n",
    "    cricterior = cricterior\n",
    "    set_feature = dict()\n",
    "    columns = df.columns.tolist()\n",
    "    len_columns = len(columns)\n",
    "    columns = list(set(columns) - set([val_class]))\n",
    "    #X_train, X_test, y_train, y_test, columns_extract_all = preprocessing_dataset_(df, [val_class], sep, val_class, random)\n",
    "    for col in columns:\n",
    "        if not col in vector:       \n",
    "            #X_train_selected, X_test_selected, columns_extract = selected_dataset_(columns_extract_all, [col], sep, X_train, X_test)\n",
    "            #means_scores, _, _, _ = model_evaluation_SFS_(X_train_selected, X_test_selected, y_train, y_test, columns_extract, columns, sep, cricterior)\n",
    "            #set_feature[col] = means_scores\n",
    "            \n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([df.columns.get_loc(col)]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([df.columns.get_loc(val_class)]))\n",
    "        \n",
    "            my_tree = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            accuracy, df_p = my_accuracy(test, my_tree, val_class)\n",
    "            _, means_scores = compute_metrics(df_p, val_class, name_montant, name_taux, name_duree)\n",
    "            set_feature[col] = means_scores\n",
    "            \n",
    "    for key, value in vector.items():\n",
    "        vector[key] = np.max(value, axis=0)\n",
    "    \n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=False)\n",
    "    set_feature = sorted(set_feature.items(), key=lambda x:x[1], reverse=False)\n",
    "    print(\"sorted_vector : \", sorted_vector)\n",
    "    print(\"set_feature : \", set_feature)\n",
    "    for ele in set_feature:\n",
    "        sorted_vector.append(ele)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def processing_feature_selection_AR_base_Multi_Loss_(df, dfv, cricterior, alpha, sep, val_class, name_montant, name_taux, name_duree, support_min_loss=0.07, metric_v=\"confidence\", threshold_min_loss=0.4, random=10, decision_tree_cs=\"decision_tree\"):\n",
    "    #dict_loss = give_dict_loss(df, name_montant)\n",
    "    #print(\"dict_loss : \", dict_loss)\n",
    "    #frequent_items_loss = apriori_loss_sensitive(dfv.astype('bool'), dict_loss, min_support_loss=support_min_loss)\n",
    "    #print(\"frequent_items_loss : \", frequent_items_loss)\n",
    "    #rules = association_rules_(frequent_items_loss, metric_v, threshold_min_loss)\n",
    "    frequent_itemsets = apriori(dfv.astype('bool'), min_support=support_min_loss, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=metric_v, min_threshold=threshold_min_loss)\n",
    "    \n",
    "    classe = val_class\n",
    "    #classe = df.columns.values[0]\n",
    "    unique_classe = list(df[classe].unique())\n",
    "    classe_name = []\n",
    "    for i in range(len(unique_classe)):\n",
    "        classe_name.append(classe + sep + str(unique_classe[i]))\n",
    "    \n",
    "    #rules['select'] = rules['consequents'].apply(lambda x: 'X1_0' in x or 'X1_1' in x)\n",
    "    rules['select'] = rules['consequents'].apply(lambda x: test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    rules['select'] = rules['antecedents'].apply(lambda x: not test_presence(classe_name, x))\n",
    "    rules = rules[ rules['select'] == True]\n",
    "    \n",
    "    rules['length_antecedents'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "    rules['length_consequents'] = rules['consequents'].apply(lambda x: len(x))\n",
    "    rules = rules[ (rules['length_antecedents'] == 1) & (rules['length_consequents'] == 1)] \n",
    "    #print(rules)\n",
    "    \n",
    "    vector = dict()\n",
    "    rules = apply_loss_rules(rules, df.copy(deep=True), sep, name_montant, name_taux, name_duree, val_class)\n",
    "\n",
    "    for i in rules.index:\n",
    "        item = list(rules['antecedents'][i])[0]\n",
    "        item = item.split(sep)[0]\n",
    "        if item == name_montant:\n",
    "            continue\n",
    "        if not item in vector:\n",
    "            vector[item] = []\n",
    "        #vector[item].append(rules['confidence_loss'][i])\n",
    "        vector[item].append(rules['confidence_loss'][i])\n",
    "    \n",
    "    dataset_y = df[val_class]\n",
    "    dataset_x = df.drop([val_class], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random)\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    test = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    index_feature_not_selected = []\n",
    "    idx_montant = df.columns.get_loc(name_montant)\n",
    "    idx_taux = df.columns.get_loc(name_taux)\n",
    "    idx_duree = df.columns.get_loc(name_duree)\n",
    "    \n",
    "    #random = 10\n",
    "    cricterior = cricterior\n",
    "    set_feature = dict()\n",
    "    columns = df.columns.tolist()\n",
    "    len_columns = len(columns)\n",
    "    columns = list(set(columns) - set([val_class]))\n",
    "    #X_train, X_test, y_train, y_test, columns_extract_all = preprocessing_dataset_(df, [val_class], sep, val_class, random)\n",
    "    for col in columns:\n",
    "        if not col in vector:       \n",
    "            #X_train_selected, X_test_selected, columns_extract = selected_dataset_(columns_extract_all, [col], sep, X_train, X_test)\n",
    "            #means_scores, _, _, _ = model_evaluation_SFS_(X_train_selected, X_test_selected, y_train, y_test, columns_extract, columns, sep, cricterior)\n",
    "            #set_feature[col] = means_scores\n",
    "            \n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([df.columns.get_loc(col)]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([df.columns.get_loc(val_class)]))\n",
    "        \n",
    "            my_tree = decision_tree_cs(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            accuracy, df_p = my_accuracy(test, my_tree, val_class)\n",
    "            _, means_scores = compute_metrics(df_p, val_class, name_montant, name_taux, name_duree)\n",
    "            set_feature[col] = means_scores\n",
    "            \n",
    "    for key, value in vector.items():\n",
    "        vector[key] = np.max(value, axis=0)\n",
    "    \n",
    "    sorted_vector = sorted(vector.items(), key=lambda x:x[1], reverse=False)\n",
    "    set_feature = sorted(set_feature.items(), key=lambda x:x[1], reverse=False)\n",
    "    print(\"sorted_vector : \", sorted_vector)\n",
    "    print(\"set_feature : \", set_feature)\n",
    "    for ele in set_feature:\n",
    "        sorted_vector.append(ele)\n",
    "\n",
    "    return sorted_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9d9c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0a25c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_SFS(X_train, X_test, y_train, y_test, criterior='entropy'):\n",
    "    model = DecisionTreeClassifier(criterion=criterior, random_state=0)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    X_data = np.concatenate((X_train, X_test), axis=0)\n",
    "    y_data = np.concatenate((y_train, y_test), axis=0)\n",
    "    scores = cross_val_score(model, X=X_data, y=y_data, cv=10, n_jobs=1)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    #print(\"Confusion Matrix : \", conf_matrix)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    \n",
    "    means_scores = np.mean(scores)\n",
    "    \n",
    "    return means_scores, conf_matrix, prec\n",
    "\n",
    "\n",
    "def feature_selection_SFS_ARFS_Sensitive_Loss(dataset, dfv, sep, name_columns_drop, name_classe, name_montant, name_taux, name_duree, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    #dataset, y_train = get_dataset_classe()\n",
    "    \n",
    "    divide = True\n",
    "    i = 0\n",
    "    j = 0\n",
    "    max_scores = float('inf')\n",
    "    sorted_vector = processing_feature_selection_AR_Sensitive_Loss(dataset, dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    #sorted_vector = processing_feature_selection_AR_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    #654sorted_vector = processing_feature_selection_AR_Inverse_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    \n",
    "    beta = len(sorted_vector)\n",
    "    opti_feature = dict()\n",
    "    suite_index = dict()\n",
    "    k = 0\n",
    "    cricterior = 'cs'\n",
    "    feature_vector = dict()\n",
    "    itera = 1\n",
    "    feature_vector[j] = []\n",
    "    train, test = train_test_split_(dataset, 0.3)\n",
    "    idx_montant = dataset.columns.get_loc(name_montant)\n",
    "    idx_taux = dataset.columns.get_loc(name_taux)\n",
    "    idx_duree = dataset.columns.get_loc(name_duree)\n",
    "    while divide == True:\n",
    "        feature_vector[j].append(sorted_vector[i][0])\n",
    "        #print(feature_vector[j])\n",
    "        ###data = dataset[np.concatenate((feature_vector[j], [name_classe]), axis=None)]\n",
    "        \n",
    "        #X_train, X_test, y_train, y_test = preprocessing_dataset(data, name_columns_drop, name_classe)\n",
    "        #means_scores, conf_matrix, prec = model_evaluation_SFS(X_train, X_test, y_train, y_test, cricterior)\n",
    "        \n",
    "        \n",
    "        index_feature_not_selected = list(set(range(len(dataset.columns.values.tolist()))) - set([dataset.columns.get_loc(col) for col in feature_vector[j]])) \n",
    "        index_feature_not_selected = list(set(index_feature_not_selected) - set([name_classe])) \n",
    "        \n",
    "        my_tree = decision_tree(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "        accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "        _, means_scores = compute_metrics(df, name_classe, name_montant, name_taux, name_duree)\n",
    "        #Use prepocessing data in X_train to transform the data before the training at the model \n",
    "        #model.fit(X_train, y_train)\n",
    "        #scores = cross_val_score(model, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "        #means_scores = np.mean(scores)\n",
    "        \n",
    "        if means_scores < max_scores:\n",
    "            max_scores = means_scores\n",
    "            opt_tree = my_tree\n",
    "            opti_feature[i] = [deepcopy(feature_vector[j]), means_scores, len(feature_vector[j]), accuracy] \n",
    "        else:\n",
    "            if means_scores == max_scores:\n",
    "                feature_vector[itera] = deepcopy(feature_vector[j])\n",
    "                suite_index[itera] = i\n",
    "                itera = itera + 1\n",
    "            else:\n",
    "                feature_vector[j].pop(len(feature_vector[j])-1)\n",
    "        #print(opti_feature)\n",
    "        if i >= beta-1:\n",
    "            if j < len(feature_vector)-1:\n",
    "                j = j + 1\n",
    "                i = suite_index[j]                \n",
    "                if i >= beta-1:\n",
    "                    divide = False\n",
    "            else:\n",
    "                divide = False\n",
    "        i = i + 1\n",
    "    return opti_feature, max_scores, sorted_vector, opt_tree\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_selection_SFS_ARFS_Sensitive_Loss_(dataset, dfv, sep, name_columns_drop, name_classe, name_montant, name_taux, name_duree, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    divide = True\n",
    "    i = 0\n",
    "    j = 0\n",
    "    train, test = train_test_split_(dataset, 0.3)\n",
    "    #sorted_vector = processing_feature_selection_AR_base_Sensitive_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    sorted_vector = processing_feature_selection_AR_base_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    #sorted_vector = processing_feature_selection_AR_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    #654sorted_vector = processing_feature_selection_AR_Inverse_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    \n",
    "    beta = len(sorted_vector)\n",
    "    opti_feature = dict()\n",
    "    suite_index = dict()\n",
    "    k = 0\n",
    "    opti_accuracy = 0.0\n",
    "    cricterior = 'cs'\n",
    "    feature_vector = dict()\n",
    "    itera = 1\n",
    "    feature_vector[j] = []\n",
    "    \n",
    "    #print(np.unique(train[:,7], return_counts = True))\n",
    "    idx_montant = dataset.columns.get_loc(name_montant)\n",
    "    idx_taux = dataset.columns.get_loc(name_taux)\n",
    "    idx_duree = dataset.columns.get_loc(name_duree)\n",
    "    max_scores = float('inf')\n",
    "    columns = dataset.columns.tolist()\n",
    "    len_columns = len(columns)\n",
    "    while divide == True:\n",
    "        feature_vector[j].append(sorted_vector[i][0])\n",
    "        ####print(\"feature_vector[j] : \", feature_vector[j])\n",
    "        #print(feature_vector[j])\n",
    "        ###data = dataset[np.concatenate((feature_vector[j], [name_classe]), axis=None)]\n",
    "        \n",
    "        #X_train, X_test, y_train, y_test = preprocessing_dataset(data, name_columns_drop, name_classe)\n",
    "        #means_scores, conf_matrix, prec = model_evaluation_SFS(X_train, X_test, y_train, y_test, cricterior)\n",
    "        \n",
    "        index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j]]))\n",
    "        index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)])) \n",
    "        \n",
    "        my_tree = decision_tree(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "        accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "        _, means_scores = compute_metrics(df, name_classe, name_montant, name_taux, name_duree)\n",
    "        \n",
    "        ####print(\"means_scores : \", means_scores)\n",
    "        ####print(\"my_tree : \", my_tree)\n",
    "        #Use prepocessing data in X_train to transform the data before the training at the model \n",
    "        #model.fit(X_train, y_train)\n",
    "        #scores = cross_val_score(model, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "        #means_scores = np.mean(scores)\n",
    "        #print(\"my_tree :\", my_tree)\n",
    "        #print(\"max_scores : \", max_scores, \"; Accuracy : \", accuracy, \" ; means_scores : \", means_scores, \"; feature_vector[j] : \", feature_vector[j], \"; index_feature_not_selected: \", index_feature_not_selected)\n",
    "        if means_scores < max_scores:\n",
    "            #print(\"tchuente\")\n",
    "            max_scores = means_scores\n",
    "            opt_tree = my_tree\n",
    "            #opti_accuracy = accuracy\n",
    "            feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "            ####print(\"feature_vector[j]& : \", feature_vector[j])\n",
    "            #print(\"feature_vector[j]-optimal: \", feature_vector[j])\n",
    "            opti_feature[i] = [deepcopy(feature_vector[j]), means_scores, len(feature_vector[j]), accuracy] \n",
    "        else:\n",
    "            if means_scores == max_scores:\n",
    "                feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                feature_vector[itera] = deepcopy(feature_vector[j])\n",
    "                suite_index[itera] = i\n",
    "                itera = itera + 1\n",
    "            else:\n",
    "                feature_vector[j].pop(len(feature_vector[j])-1)\n",
    "        #print(opti_feature)\n",
    "        if i >= beta-1:\n",
    "            if j < len(feature_vector)-1:\n",
    "                j = j + 1\n",
    "                i = suite_index[j]                \n",
    "                if i >= beta-1:\n",
    "                    divide = False\n",
    "            else:\n",
    "                divide = False\n",
    "        i = i + 1\n",
    "    index_feature_not_selected = []\n",
    "    my_tree = decision_tree(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "    accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "    results_all_data = compute_metrics(df, name_classe, name_montant, name_taux, name_duree), extract_feature_select_tree(my_tree)    \n",
    "    \n",
    "    return opti_feature, max_scores, sorted_vector, opt_tree, results_all_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_selection_SFS_ARFS_Sensitive_Multi_Loss(dataset, dfv, sep, type_cout, alpha, name_columns_drop, name_classe, name_montant,\n",
    "                                                    name_taux, name_duree, cricterior, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4):\n",
    "    divide = True\n",
    "    i = 0\n",
    "    j = 0\n",
    "    train, test = train_test_split_(dataset, 0.3)\n",
    "    #sorted_vector = processing_feature_selection_AR_base_Sensitive_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    #sorted_vector = processing_feature_selection_AR_base_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    sorted_vector = processing_feature_selection_AR_base_Multi_Loss(dataset.copy(), dfv, cricterior, alpha, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    #sorted_vector = processing_feature_selection_AR_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    #654sorted_vector = processing_feature_selection_AR_Inverse_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    \n",
    "    beta = len(sorted_vector)\n",
    "    opti_feature = dict()\n",
    "    suite_index = dict()\n",
    "    k = 0\n",
    "    opti_accuracy = 0.0\n",
    "    cricterior = cricterior\n",
    "    feature_vector = dict()\n",
    "    itera = 1\n",
    "    feature_vector[j] = []\n",
    "    \n",
    "    #print(np.unique(train[:,7], return_counts = True))\n",
    "    idx_montant = dataset.columns.get_loc(name_montant)\n",
    "    idx_taux = dataset.columns.get_loc(name_taux)\n",
    "    idx_duree = dataset.columns.get_loc(name_duree)\n",
    "    optimisation_minimisation = [\"pessimiste\"]\n",
    "    optimisation_maximisation = [\"total\", \"optimiste\", \"reel\"]\n",
    "    \n",
    "    if type_cout in optimisation_minimisation:\n",
    "        max_scores = float('inf')\n",
    "    elif type_cout in optimisation_maximisation:\n",
    "        max_scores = -float('inf')\n",
    "        \n",
    "    columns = dataset.columns.tolist()\n",
    "    len_columns = len(columns)\n",
    "    opt_tree = []\n",
    "    \n",
    "    while divide == True:\n",
    "        feature_vector[j].append(sorted_vector[i][0])\n",
    "        #print(\"feature_vector[j] : \", feature_vector[j])\n",
    "        #print(feature_vector[j])\n",
    "        ###data = dataset[np.concatenate((feature_vector[j], [name_classe]), axis=None)]\n",
    "        \n",
    "        #X_train, X_test, y_train, y_test = preprocessing_dataset(data, name_columns_drop, name_classe)\n",
    "        #means_scores, conf_matrix, prec = model_evaluation_SFS(X_train, X_test, y_train, y_test, cricterior)\n",
    "        \n",
    "        index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j]]))\n",
    "        index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)])) \n",
    "        \n",
    "        my_tree = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "        accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "        #_, means_scores = compute_metrics(df, name_classe, name_montant, name_taux, name_duree)\n",
    "        _, means_scores = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "        \n",
    "        #print(\"means_scores : \", means_scores)\n",
    "        #print(\"my_tree : \", my_tree)\n",
    "        #Use prepocessing data in X_train to transform the data before the training at the model \n",
    "        #model.fit(X_train, y_train)\n",
    "        #scores = cross_val_score(model, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "        #means_scores = np.mean(scores)\n",
    "        #print(\"my_tree :\", my_tree)\n",
    "        #print(\"max_scores : \", max_scores, \"; Accuracy : \", accuracy, \" ; means_scores : \", means_scores, \"; feature_vector[j] : \", feature_vector[j], \"; index_feature_not_selected: \", index_feature_not_selected)\n",
    "        if type_cout in optimisation_minimisation:\n",
    "            if means_scores < max_scores:\n",
    "                #print(\"tchuente\")\n",
    "                max_scores = means_scores\n",
    "                opt_tree = my_tree\n",
    "                #opti_accuracy = accuracy\n",
    "                if type(my_tree) is dict:    \n",
    "                    feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                #print(\"feature_vector[j]& : \", feature_vector[j])\n",
    "                #print(\"feature_vector[j]-optimal: \", feature_vector[j])\n",
    "                opti_feature[i] = [deepcopy(feature_vector[j]), means_scores, len(feature_vector[j]), accuracy] \n",
    "            else:\n",
    "                if means_scores == max_scores:\n",
    "                    if type(my_tree) is dict:    \n",
    "                        feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    ####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    feature_vector[itera] = deepcopy(feature_vector[j])\n",
    "                    suite_index[itera] = i\n",
    "                    itera = itera + 1\n",
    "                else:\n",
    "                    feature_vector[j].pop(len(feature_vector[j])-1)\n",
    "        elif type_cout in optimisation_maximisation:\n",
    "            if means_scores > max_scores:\n",
    "                #print(\"tchuente\")\n",
    "                max_scores = means_scores\n",
    "                opt_tree = my_tree\n",
    "                #opti_accuracy = accuracy\n",
    "                if type(my_tree) is dict:    \n",
    "                    feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                #####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                ####print(\"feature_vector[j]& : \", feature_vector[j])\n",
    "                #print(\"feature_vector[j]-optimal: \", feature_vector[j])\n",
    "                opti_feature[i] = [deepcopy(feature_vector[j]), means_scores, len(feature_vector[j]), accuracy] \n",
    "            else:\n",
    "                if means_scores == max_scores:\n",
    "                    ####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    if type(my_tree) is dict:    \n",
    "                        feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    feature_vector[itera] = deepcopy(feature_vector[j])\n",
    "                    suite_index[itera] = i\n",
    "                    itera = itera + 1\n",
    "                else:\n",
    "                    feature_vector[j].pop(len(feature_vector[j])-1)\n",
    "            \n",
    "        #print(opti_feature)\n",
    "        if i >= beta-1:\n",
    "            if j < len(feature_vector)-1:\n",
    "                j = j + 1\n",
    "                i = suite_index[j]                \n",
    "                if i >= beta-1:\n",
    "                    divide = False\n",
    "            else:\n",
    "                divide = False\n",
    "        i = i + 1\n",
    "    index_feature_not_selected = []\n",
    "    my_tree = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "    accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "    results_all_data = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree), extract_feature_select_tree(my_tree)    \n",
    "    return opti_feature, max_scores, sorted_vector, opt_tree, results_all_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_selection_SFS_ARFS_Sensitive_Multi_Loss_(dataset, dfv, sep, type_cout, alpha, name_columns_drop, name_classe, name_montant,\n",
    "                                                    name_taux, name_duree, cricterior, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4, random=10):\n",
    "    divide = True\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    dataset_y = dataset[name_classe]\n",
    "    dataset_x = dataset.drop(name_columns_drop, axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random)\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    test = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    \n",
    "    #sorted_vector = processing_feature_selection_AR_base_Sensitive_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    #sorted_vector = processing_feature_selection_AR_base_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    sorted_vector = processing_feature_selection_AR_base_Multi_Loss(dataset.copy(), dfv, cricterior, alpha, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min, random)\n",
    "    #sorted_vector = processing_feature_selection_AR_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    #654sorted_vector = processing_feature_selection_AR_Inverse_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    \n",
    "    beta = len(sorted_vector)\n",
    "    opti_feature = dict()\n",
    "    suite_index = dict()\n",
    "    k = 0\n",
    "    opti_accuracy = 0.0\n",
    "    cricterior = cricterior\n",
    "    feature_vector = dict()\n",
    "    itera = 1\n",
    "    feature_vector[j] = deepcopy([deepcopy([]), deepcopy([])])    \n",
    "    #print(np.unique(train[:,7], return_counts = True))\n",
    "    idx_montant = dataset.columns.get_loc(name_montant)\n",
    "    idx_taux = dataset.columns.get_loc(name_taux)\n",
    "    idx_duree = dataset.columns.get_loc(name_duree)\n",
    "    optimisation_minimisation = [\"pessimiste\"]\n",
    "    optimisation_maximisation = [\"total\", \"optimiste\", \"reel\"]\n",
    "    \n",
    "    if type_cout in optimisation_minimisation:\n",
    "        max_scores = float('inf')\n",
    "    elif type_cout in optimisation_maximisation:\n",
    "        max_scores = -float('inf')\n",
    "    max_scores_acc = -float('inf')    \n",
    "    columns = dataset.columns.tolist()\n",
    "    len_columns = len(columns)\n",
    "    opt_tree = []\n",
    "    \n",
    "    while divide == True:\n",
    "        feature_vector[j][0].append(sorted_vector[i][0])\n",
    "        feature_vector[j][1].append(sorted_vector[i][0])\n",
    "        #print(\"feature_vector[j] : \", feature_vector[j])\n",
    "        #print(feature_vector[j])\n",
    "        ###data = dataset[np.concatenate((feature_vector[j], [name_classe]), axis=None)]\n",
    "        \n",
    "        #X_train, X_test, y_train, y_test = preprocessing_dataset(data, name_columns_drop, name_classe)\n",
    "        #means_scores, conf_matrix, prec = model_evaluation_SFS(X_train, X_test, y_train, y_test, cricterior)\n",
    "        \n",
    "        #index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j]]))\n",
    "        #index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)])) \n",
    "\n",
    "        if feature_vector[j][0] != []:\n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j][0]]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "            my_tree_gen = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            accuracy_gen, df_gen = my_accuracy(test, my_tree_gen, name_classe)\n",
    "            result_gen, means_scores_gen = compute_metrics_derive(df_gen, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "            #print(\"index_feature_not_selected : \", index_feature_not_selected)\n",
    "            #print(\"feature_vector[j][0] : \", feature_vector[j][0])\n",
    "            #print(\"accuracy_sel : \", means_scores_gen)\n",
    "\n",
    "        \n",
    "        if feature_vector[j][1] != []:\n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j][1]]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "            my_tree_sel = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            accuracy_sel, df_sel = my_accuracy(test, my_tree_sel, name_classe)\n",
    "            result_sel, means_scores_sel = compute_metrics_derive(df_sel, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "            \n",
    "        #print(\"means_scores : \", means_scores)\n",
    "        #print(\"my_tree : \", my_tree)\n",
    "        #Use prepocessing data in X_train to transform the data before the training at the model \n",
    "        #model.fit(X_train, y_train)\n",
    "        #scores = cross_val_score(model, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "        #means_scores = np.mean(scores)\n",
    "        #print(\"my_tree :\", my_tree)\n",
    "        #print(\"max_scores : \", max_scores, \"; Accuracy : \", accuracy, \" ; means_scores : \", means_scores, \"; feature_vector[j] : \", feature_vector[j], \"; index_feature_not_selected: \", index_feature_not_selected)\n",
    "                \n",
    "        \n",
    "        if type_cout in optimisation_minimisation:\n",
    "            if means_scores_sel <= means_scores_gen:\n",
    "                means_scores = means_scores_sel\n",
    "                accuracy = accuracy_sel\n",
    "                my_tree = my_tree_sel\n",
    "                result = result_sel\n",
    "            else:\n",
    "                means_scores = means_scores_gen\n",
    "                accuracy = accuracy_gen\n",
    "                my_tree = my_tree_gen\n",
    "                result = result_gen\n",
    "\n",
    "            if means_scores < max_scores:#if means_scores < max_scores and accuracy > max_scores_acc:\n",
    "                #print(\"tchuente\")\n",
    "                max_scores = means_scores\n",
    "                opt_tree = my_tree\n",
    "                max_scores_acc = accuracy\n",
    "                #opti_accuracy = accuracy\n",
    "                if type(my_tree) is dict:    \n",
    "                    feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                #print(\"feature_vector[j]& : \", feature_vector[j])\n",
    "                #print(\"feature_vector[j]-optimal: \", feature_vector[j])\n",
    "                opti_feature[i] = [deepcopy(feature_vector[j][1]), means_scores, len(feature_vector[j][1]), accuracy, result] \n",
    "            else:\n",
    "                if means_scores == max_scores:#if means_scores == max_scores:\n",
    "                    if type(my_tree) is dict:    \n",
    "                        feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    ####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    feature_vector[itera] = deepcopy([deepcopy(feature_vector[j][0]), deepcopy(feature_vector[j][1])])\n",
    "                    suite_index[itera] = i\n",
    "                    itera = itera + 1\n",
    "                else:\n",
    "                    #feature_vector[j][0].pop(len(feature_vector[j][0])-1)\n",
    "                    feature_vector[j][1].pop(len(feature_vector[j][1])-1)\n",
    "        elif type_cout in optimisation_maximisation:\n",
    "            if means_scores_sel >= means_scores_gen:\n",
    "                means_scores = means_scores_sel\n",
    "                accuracy = accuracy_sel\n",
    "                my_tree = my_tree_sel\n",
    "                result = result_sel\n",
    "            else:\n",
    "                means_scores = means_scores_gen\n",
    "                accuracy = accuracy_gen\n",
    "                my_tree = my_tree_gen\n",
    "                result = result_gen\n",
    "\n",
    "            if means_scores > max_scores:#if means_scores > max_scores and accuracy > max_scores_acc:\n",
    "                #print(\"tchuente\")\n",
    "                max_scores = means_scores\n",
    "                max_scores_acc = accuracy\n",
    "                opt_tree = my_tree\n",
    "                #opti_accuracy = accuracy\n",
    "                if type(my_tree) is dict:    \n",
    "                    feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                #####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                ####print(\"feature_vector[j]& : \", feature_vector[j])\n",
    "                #print(\"feature_vector[j]-optimal: \", feature_vector[j])\n",
    "                opti_feature[i] = [deepcopy(feature_vector[j][1]), means_scores, len(feature_vector[j][1]), accuracy, result] \n",
    "            else:\n",
    "                if means_scores == max_scores:\n",
    "                    ####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    if type(my_tree) is dict:    \n",
    "                        feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    feature_vector[itera] = deepcopy([deepcopy(feature_vector[j][0]), deepcopy(feature_vector[j][1])])\n",
    "                    suite_index[itera] = i\n",
    "                    itera = itera + 1\n",
    "                else:\n",
    "                    #feature_vector[j][0].pop(len(feature_vector[j][0])-1)\n",
    "                    feature_vector[j][1].pop(len(feature_vector[j][1])-1)\n",
    "            \n",
    "        #print(opti_feature)\n",
    "        if i >= beta-1:\n",
    "            if j < len(feature_vector)-1:\n",
    "                j = j + 1\n",
    "                i = suite_index[j]                \n",
    "                if i >= beta-1:\n",
    "                    divide = False\n",
    "            else:\n",
    "                divide = False\n",
    "        i = i + 1\n",
    "    index_feature_not_selected = []\n",
    "    my_tree = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "    accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "    results_all_data = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree), extract_feature_select_tree(my_tree)    \n",
    "    return opti_feature, max_scores, sorted_vector, opt_tree, results_all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11266a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_SFS_ARFS_Sensitive_Multi_Loss_(dataset, dfv, sep, type_cout, alpha, name_columns_drop, name_classe, name_montant,\n",
    "                                                    name_taux, name_duree, cricterior, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4, random=10):\n",
    "    divide = True\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    dataset_y = dataset[name_classe]\n",
    "    dataset_x = dataset.drop(name_columns_drop, axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random)\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    test = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    \n",
    "    #sorted_vector = processing_feature_selection_AR_base_Sensitive_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    #sorted_vector = processing_feature_selection_AR_base_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    sorted_vector = processing_feature_selection_AR_base_Multi_Loss(dataset.copy(), dfv, cricterior, alpha, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min, random)\n",
    "    #sorted_vector = processing_feature_selection_AR_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    #654sorted_vector = processing_feature_selection_AR_Inverse_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    \n",
    "    beta = len(sorted_vector)\n",
    "    opti_feature = dict()\n",
    "    suite_index = dict()\n",
    "    k = 0\n",
    "    opti_accuracy = 0.0\n",
    "    cricterior = cricterior\n",
    "    feature_vector = dict()\n",
    "    itera = 1\n",
    "    feature_vector[j] = deepcopy([deepcopy([]), deepcopy([])])    \n",
    "    #print(np.unique(train[:,7], return_counts = True))\n",
    "    idx_montant = dataset.columns.get_loc(name_montant)\n",
    "    idx_taux = dataset.columns.get_loc(name_taux)\n",
    "    idx_duree = dataset.columns.get_loc(name_duree)\n",
    "    optimisation_minimisation = [\"pessimiste\"]\n",
    "    optimisation_maximisation = [\"total\", \"optimiste\", \"reel\"]\n",
    "    \n",
    "    if type_cout in optimisation_minimisation:\n",
    "        max_scores = float('inf')\n",
    "    elif type_cout in optimisation_maximisation:\n",
    "        max_scores = -float('inf')\n",
    "    max_scores_acc = -float('inf')    \n",
    "    columns = dataset.columns.tolist()\n",
    "    len_columns = len(columns)\n",
    "    opt_tree = []\n",
    "    \n",
    "    while divide == True:\n",
    "        feature_vector[j][0].append(sorted_vector[i][0])\n",
    "        feature_vector[j][1].append(sorted_vector[i][0])\n",
    "        #print(\"feature_vector[j] : \", feature_vector[j])\n",
    "        #print(feature_vector[j])\n",
    "        ###data = dataset[np.concatenate((feature_vector[j], [name_classe]), axis=None)]\n",
    "        \n",
    "        #X_train, X_test, y_train, y_test = preprocessing_dataset(data, name_columns_drop, name_classe)\n",
    "        #means_scores, conf_matrix, prec = model_evaluation_SFS(X_train, X_test, y_train, y_test, cricterior)\n",
    "        \n",
    "        #index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j]]))\n",
    "        #index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)])) \n",
    "\n",
    "        if feature_vector[j][0] != []:\n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j][0]]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "            my_tree_gen = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            accuracy_gen, df_gen = my_accuracy(test, my_tree_gen, name_classe)\n",
    "            result_gen, means_scores_gen = compute_metrics_derive(df_gen, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "            #print(\"index_feature_not_selected : \", index_feature_not_selected)\n",
    "            #print(\"feature_vector[j][0] : \", feature_vector[j][0])\n",
    "            #print(\"accuracy_sel : \", means_scores_gen)\n",
    "\n",
    "        \n",
    "        if feature_vector[j][1] != []:\n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j][1]]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "            my_tree_sel = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            accuracy_sel, df_sel = my_accuracy(test, my_tree_sel, name_classe)\n",
    "            result_sel, means_scores_sel = compute_metrics_derive(df_sel, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "            \n",
    "        #print(\"means_scores : \", means_scores)\n",
    "        #print(\"my_tree : \", my_tree)\n",
    "        #Use prepocessing data in X_train to transform the data before the training at the model \n",
    "        #model.fit(X_train, y_train)\n",
    "        #scores = cross_val_score(model, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "        #means_scores = np.mean(scores)\n",
    "        #print(\"my_tree :\", my_tree)\n",
    "        #print(\"max_scores : \", max_scores, \"; Accuracy : \", accuracy, \" ; means_scores : \", means_scores, \"; feature_vector[j] : \", feature_vector[j], \"; index_feature_not_selected: \", index_feature_not_selected)\n",
    "                \n",
    "        \n",
    "        if type_cout in optimisation_minimisation:\n",
    "            if means_scores_sel <= means_scores_gen:\n",
    "                means_scores = means_scores_sel\n",
    "                accuracy = accuracy_sel\n",
    "                my_tree = my_tree_sel\n",
    "                result = result_sel\n",
    "            else:\n",
    "                means_scores = means_scores_gen\n",
    "                accuracy = accuracy_gen\n",
    "                my_tree = my_tree_gen\n",
    "                result = result_gen\n",
    "\n",
    "            if means_scores < max_scores:#if means_scores < max_scores and accuracy > max_scores_acc:\n",
    "                #print(\"tchuente\")\n",
    "                max_scores = means_scores\n",
    "                opt_tree = my_tree\n",
    "                max_scores_acc = accuracy\n",
    "                #opti_accuracy = accuracy\n",
    "                if type(my_tree) is dict:    \n",
    "                    feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                #print(\"feature_vector[j]& : \", feature_vector[j])\n",
    "                #print(\"feature_vector[j]-optimal: \", feature_vector[j])\n",
    "                opti_feature[i] = [deepcopy(feature_vector[j][1]), means_scores, len(feature_vector[j][1]), accuracy, result] \n",
    "            else:\n",
    "                if means_scores == max_scores:#if means_scores == max_scores:\n",
    "                    if type(my_tree) is dict:    \n",
    "                        feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    ####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    feature_vector[itera] = deepcopy([deepcopy(feature_vector[j][0]), deepcopy(feature_vector[j][1])])\n",
    "                    suite_index[itera] = i\n",
    "                    itera = itera + 1\n",
    "                else:\n",
    "                    #feature_vector[j][0].pop(len(feature_vector[j][0])-1)\n",
    "                    feature_vector[j][1].pop(len(feature_vector[j][1])-1)\n",
    "        elif type_cout in optimisation_maximisation:\n",
    "            if means_scores_sel >= means_scores_gen:\n",
    "                means_scores = means_scores_sel\n",
    "                accuracy = accuracy_sel\n",
    "                my_tree = my_tree_sel\n",
    "                result = result_sel\n",
    "            else:\n",
    "                means_scores = means_scores_gen\n",
    "                accuracy = accuracy_gen\n",
    "                my_tree = my_tree_gen\n",
    "                result = result_gen\n",
    "\n",
    "            if means_scores > max_scores:#if means_scores > max_scores and accuracy > max_scores_acc:\n",
    "                #print(\"tchuente\")\n",
    "                max_scores = means_scores\n",
    "                max_scores_acc = accuracy\n",
    "                opt_tree = my_tree\n",
    "                #opti_accuracy = accuracy\n",
    "                if type(my_tree) is dict:    \n",
    "                    feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                #####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                ####print(\"feature_vector[j]& : \", feature_vector[j])\n",
    "                #print(\"feature_vector[j]-optimal: \", feature_vector[j])\n",
    "                opti_feature[i] = [deepcopy(feature_vector[j][1]), means_scores, len(feature_vector[j][1]), accuracy, result] \n",
    "            else:\n",
    "                if means_scores == max_scores:\n",
    "                    ####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    if type(my_tree) is dict:    \n",
    "                        feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    feature_vector[itera] = deepcopy([deepcopy(feature_vector[j][0]), deepcopy(feature_vector[j][1])])\n",
    "                    suite_index[itera] = i\n",
    "                    itera = itera + 1\n",
    "                else:\n",
    "                    #feature_vector[j][0].pop(len(feature_vector[j][0])-1)\n",
    "                    feature_vector[j][1].pop(len(feature_vector[j][1])-1)\n",
    "            \n",
    "        #print(opti_feature)\n",
    "        if i >= beta-1:\n",
    "            if j < len(feature_vector)-1:\n",
    "                j = j + 1\n",
    "                i = suite_index[j]                \n",
    "                if i >= beta-1:\n",
    "                    divide = False\n",
    "            else:\n",
    "                divide = False\n",
    "        i = i + 1\n",
    "    index_feature_not_selected = []\n",
    "    my_tree = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "    accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "    results_all_data = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree), extract_feature_select_tree(my_tree)    \n",
    "    return opti_feature, max_scores, sorted_vector, opt_tree, results_all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed2ad40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_element_list(list_element_at_remove, set_element):\n",
    "    print(\"list_element_at_remove : \", list_element_at_remove)\n",
    "    print(\"set_element : \", set_element)\n",
    "    for i in range(len(list_element_at_remove)):\n",
    "        delete = False\n",
    "        j = 0\n",
    "        while delete == False and j < len(set_element):\n",
    "            if list_element_at_remove[i] == set_element[j][0]:\n",
    "                delete = True\n",
    "                set_element.remove(set_element[j])\n",
    "            else:\n",
    "                j = j + 1\n",
    "    print(\"set_element results : \", set_element)\n",
    "    return set_element\n",
    "\n",
    "\n",
    "def feature_selection_SFS_ARFS_Sensitive_Multi_Loss_Boosting(dataset, dfv, sep, type_cout, alpha, name_columns_drop, name_classe, name_montant,\n",
    "                                                    name_taux, name_duree, cricterior, nb_estimator = 5, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4, random=10):\n",
    "    divide = True\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    dataset_y = dataset[name_classe]\n",
    "    dataset_x = dataset.drop(name_columns_drop, axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random)\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    test = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    \n",
    "    #sorted_vector = processing_feature_selection_AR_base_Sensitive_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    #sorted_vector = processing_feature_selection_AR_base_Loss_(dataset.copy(), dfv, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min)\n",
    "    sorted_vector = processing_feature_selection_AR_base_Multi_Loss(dataset.copy(), dfv, cricterior, alpha, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min, random)\n",
    "    #sorted_vector = processing_feature_selection_AR_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    #654sorted_vector = processing_feature_selection_AR_Inverse_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    \n",
    "    beta = len(sorted_vector)\n",
    "    opti_feature = dict()\n",
    "    opti_feature_boost = dict()\n",
    "    list_of_opti_feature = deepcopy([])\n",
    "    suite_index = dict()\n",
    "    k = 0\n",
    "    opti_accuracy = 0.0\n",
    "    cricterior = cricterior\n",
    "    feature_vector = dict()\n",
    "    itera = 1\n",
    "    feature_vector[j] = deepcopy([deepcopy([]), deepcopy([])])\n",
    "    idx_montant = dataset.columns.get_loc(name_montant)\n",
    "    idx_taux = dataset.columns.get_loc(name_taux)\n",
    "    idx_duree = dataset.columns.get_loc(name_duree)\n",
    "    optimisation_minimisation = [\"pessimiste\"]\n",
    "    optimisation_maximisation = [\"total\", \"optimiste\", \"reel\"]\n",
    "    \n",
    "    if type_cout in optimisation_minimisation:\n",
    "        max_scores = float('inf')\n",
    "    elif type_cout in optimisation_maximisation:\n",
    "        max_scores = -float('inf')\n",
    "    max_scores_acc = -float('inf')    \n",
    "    columns = dataset.columns.tolist()\n",
    "    len_columns = len(columns)\n",
    "    opt_tree = deepcopy([])\n",
    "    index_opti_feature = None\n",
    "    for estimator_i in range(nb_estimator):\n",
    "        while divide == True:\n",
    "            feature_vector[j][0].append(sorted_vector[i][0])\n",
    "            feature_vector[j][1].append(sorted_vector[i][0])\n",
    "            #print(\"feature_vector[j] : \", feature_vector[j])\n",
    "            #print(feature_vector[j])\n",
    "            ###data = dataset[np.concatenate((feature_vector[j], [name_classe]), axis=None)]\n",
    "\n",
    "            #X_train, X_test, y_train, y_test = preprocessing_dataset(data, name_columns_drop, name_classe)\n",
    "            #means_scores, conf_matrix, prec = model_evaluation_SFS(X_train, X_test, y_train, y_test, cricterior)\n",
    "\n",
    "            #index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j]]))\n",
    "            #index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)])) \n",
    "\n",
    "            if feature_vector[j][0] != []:\n",
    "                index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j][0]]))\n",
    "                index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "                my_tree_gen = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "                accuracy_gen, df_gen = my_accuracy(test, my_tree_gen, name_classe)\n",
    "                result_gen, means_scores_gen = compute_metrics_derive(df_gen, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "\n",
    "            if feature_vector[j][1] != []:\n",
    "                index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j][1]]))\n",
    "                index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "                my_tree_sel = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "                accuracy_sel, df_sel = my_accuracy(test, my_tree_sel, name_classe)\n",
    "                result_sel, means_scores_sel = compute_metrics_derive(df_sel, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "\n",
    "            #print(\"means_scores : \", means_scores)\n",
    "            #print(\"my_tree : \", my_tree)\n",
    "            #Use prepocessing data in X_train to transform the data before the training at the model \n",
    "            #model.fit(X_train, y_train)\n",
    "            #scores = cross_val_score(model, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "            #means_scores = np.mean(scores)\n",
    "            #print(\"my_tree :\", my_tree)\n",
    "            #print(\"max_scores : \", max_scores, \"; Accuracy : \", accuracy, \" ; means_scores : \", means_scores, \"; feature_vector[j] : \", feature_vector[j], \"; index_feature_not_selected: \", index_feature_not_selected)\n",
    "\n",
    "\n",
    "            if type_cout in optimisation_minimisation:\n",
    "                if means_scores_sel <= means_scores_gen:\n",
    "                    means_scores = means_scores_sel\n",
    "                    accuracy = accuracy_sel\n",
    "                    my_tree = my_tree_sel\n",
    "                    result = result_sel\n",
    "                else:\n",
    "                    means_scores = means_scores_gen\n",
    "                    accuracy = accuracy_gen\n",
    "                    my_tree = my_tree_gen\n",
    "                    result = result_gen\n",
    "\n",
    "                if means_scores < max_scores:#if means_scores < max_scores and accuracy > max_scores_acc:\n",
    "                    #print(\"tchuente\")\n",
    "                    max_scores = means_scores\n",
    "                    opt_tree = my_tree\n",
    "                    max_scores_acc = accuracy\n",
    "                    #opti_accuracy = accuracy\n",
    "                    if type(my_tree) is dict:    \n",
    "                        feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    #print(\"feature_vector[j]& : \", feature_vector[j])\n",
    "                    #print(\"feature_vector[j]-optimal: \", feature_vector[j])\n",
    "                    opti_feature[i] = [deepcopy(feature_vector[j][1]), means_scores, len(feature_vector[j][1]), accuracy, result]\n",
    "                    index_opti_feature = i\n",
    "                else:\n",
    "                    if means_scores == max_scores:#if means_scores == max_scores:\n",
    "                        if type(my_tree) is dict:    \n",
    "                            feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                        ####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                        feature_vector[itera] = deepcopy([deepcopy(feature_vector[j][0]), deepcopy(feature_vector[j][1])])\n",
    "                        suite_index[itera] = i\n",
    "                        itera = itera + 1\n",
    "                    else:\n",
    "                        #feature_vector[j][0].pop(len(feature_vector[j][0])-1)\n",
    "                        feature_vector[j][1].pop(len(feature_vector[j][1])-1)\n",
    "            elif type_cout in optimisation_maximisation:\n",
    "                if means_scores_sel >= means_scores_gen:\n",
    "                    means_scores = means_scores_sel\n",
    "                    accuracy = accuracy_sel\n",
    "                    my_tree = my_tree_sel\n",
    "                    result = result_sel\n",
    "                else:\n",
    "                    means_scores = means_scores_gen\n",
    "                    accuracy = accuracy_gen\n",
    "                    my_tree = my_tree_gen\n",
    "                    result = result_gen\n",
    "\n",
    "                if means_scores > max_scores:#if means_scores > max_scores and accuracy > max_scores_acc:\n",
    "                    #print(\"tchuente\")\n",
    "                    max_scores = means_scores\n",
    "                    max_scores_acc = accuracy\n",
    "                    opt_tree = my_tree\n",
    "                    #opti_accuracy = accuracy\n",
    "                    if type(my_tree) is dict:    \n",
    "                        feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    #####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                    ####print(\"feature_vector[j]& : \", feature_vector[j])\n",
    "                    #print(\"feature_vector[j]-optimal: \", feature_vector[j])\n",
    "                    opti_feature[i] = [deepcopy(feature_vector[j][1]), means_scores, len(feature_vector[j][1]), accuracy, result]\n",
    "                    index_opti_feature = i\n",
    "                else:\n",
    "                    if means_scores == max_scores:\n",
    "                        ####feature_vector[j] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                        if type(my_tree) is dict:    \n",
    "                            feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "                        feature_vector[itera] = deepcopy([deepcopy(feature_vector[j][0]), deepcopy(feature_vector[j][1])])\n",
    "                        suite_index[itera] = i\n",
    "                        itera = itera + 1\n",
    "                    else:\n",
    "                        #feature_vector[j][0].pop(len(feature_vector[j][0])-1)\n",
    "                        feature_vector[j][1].pop(len(feature_vector[j][1])-1)\n",
    "\n",
    "            #print(opti_feature)\n",
    "            if i >= beta-1:\n",
    "                if j < len(feature_vector)-1:\n",
    "                    j = j + 1\n",
    "                    i = suite_index[j]                \n",
    "                    if i >= beta-1:\n",
    "                        divide = False\n",
    "                else:\n",
    "                    divide = False\n",
    "            i = i + 1\n",
    "        \n",
    "        i = 0\n",
    "        j = 0\n",
    "        k = 0\n",
    "        itera = 1\n",
    "        divide = True\n",
    "        \n",
    "        if index_opti_feature != None:\n",
    "            pred_feature_selected = deepcopy(opti_feature[index_opti_feature])\n",
    "            sorted_vector = delete_element_list(pred_feature_selected[0], sorted_vector)\n",
    "            if sorted_vector == []:\n",
    "                 break\n",
    "            feature_vector = dict()\n",
    "            feature_vector[j] = deepcopy([deepcopy(pred_feature_selected[0]), deepcopy(pred_feature_selected[0])])\n",
    "            opti_feature_boost[estimator_i] = deepcopy(pred_feature_selected)\n",
    "            list_of_opti_feature.append(opti_feature)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        print(\"sorted_vector : \", sorted_vector, \"\\n\")\n",
    "        print(\"Opti_feature : \", opti_feature, \"\\n\")\n",
    "        index_opti_feature = None\n",
    "        beta = len(sorted_vector)\n",
    "        opti_feature = dict()\n",
    "        suite_index = dict()\n",
    "        \n",
    "        \"\"\"if type_cout in optimisation_minimisation:\n",
    "            max_scores = float('inf')\n",
    "        elif type_cout in optimisation_maximisation:\n",
    "            max_scores = -float('inf')\n",
    "        \"\"\"\n",
    "    index_feature_not_selected = []\n",
    "    my_tree = decision_tree_2(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "    accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "    results_all_data = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree), extract_feature_select_tree(my_tree)    \n",
    "    return opti_feature, max_scores, sorted_vector, opt_tree, results_all_data, opti_feature_boost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f227389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebff7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_cs(X_frame, y_frame, decision_tree_cs, index_feature_not_selected, type_cout, alpha, name_classe, name_montant, name_taux, name_duree, cricterior, columns_, random, cv):\n",
    "    idx_montant = X_frame.columns.get_loc(name_montant)\n",
    "    idx_taux = X_frame.columns.get_loc(name_taux)\n",
    "    idx_duree = X_frame.columns.get_loc(name_duree)\n",
    "    #print(\"y_frame : \", y_frame)\n",
    "    X = X_frame.to_numpy()\n",
    "    y_len = len(y_frame)\n",
    "    y = y_frame.to_numpy().reshape((y_len, 1))\n",
    "    if cv==1 :\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random)\n",
    "        X_train = np.concatenate((X_train, y_train), axis=1)\n",
    "        X_test = np.concatenate((X_test, y_test), axis=1)\n",
    "        train = pd.DataFrame(data = X_train, columns = columns_)\n",
    "        test = pd.DataFrame(data = X_test, columns = columns_)\n",
    "        my_tree = decision_tree_cs(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "        accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "        result_, score = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "        return score, result_, accuracy\n",
    "    else:\n",
    "        scores = []\n",
    "        accuracys = [] \n",
    "        precisions = [] \n",
    "        recalls = []\n",
    "        accuracy_s = []\n",
    "        loss_s = []\n",
    "        kf = KFold(n_splits=cv, shuffle=True, random_state=random)\n",
    "        for train_indices, test_indices in kf.split(X):\n",
    "            X_train, y_train = X[train_indices], y[train_indices]\n",
    "            X_test, y_test = X[test_indices], y[test_indices]\n",
    "            #print(\"X_train :\", X_train)\n",
    "            #print(\"y_train :\", y_train)\n",
    "            X_train = np.concatenate((X_train, y_train), axis=1)\n",
    "            X_test = np.concatenate((X_test, y_test), axis=1)\n",
    "            X_train = pd.DataFrame(data = X_train, columns = columns_)\n",
    "            X_test = pd.DataFrame(data = X_test, columns = columns_)\n",
    "            #print(\"X_train' :\", X_train)\n",
    "            #print(\"y_train' :\", y_train)\n",
    "            my_tree = decision_tree_cs(X_train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            accuracy_, df = my_accuracy(X_test, my_tree, name_classe)\n",
    "            result_, score = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "            loss, accuracy, precision, recall = result_\n",
    "            accuracy_s.append(accuracy_)\n",
    "            accuracys.append(accuracy)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            loss_s.append(loss)\n",
    "            scores.append(score)\n",
    "        #print(\"scores : \", scores, \" , mean : \", mean(scores))    \n",
    "        result_ = (mean(loss_s), mean(accuracys), mean(precisions), mean(recalls))    \n",
    "        return mean(scores), result_, mean(accuracy_s)\n",
    "\n",
    "\n",
    "def permute_weight(sorted_vector, feature_selected, features_dict):\n",
    "    sub_feature = sorted_vector[:len(feature_selected)]\n",
    "    p_vector = []\n",
    "    for c in sub_feature:\n",
    "        p_vector.append((c, features_dict[c]))\n",
    "        \n",
    "    s_vector = []\n",
    "    for c in feature_selected:\n",
    "        s_vector.append((c, features_dict[c]))\n",
    "        \n",
    "    p_vector = sorted(p_vector, key=lambda x:x[1][1], reverse=True)\n",
    "    s_vector = sorted(s_vector, key=lambda x:x[1][1], reverse=True)\n",
    "\n",
    "    \n",
    "    for m in range(len(p_vector)):\n",
    "        temp = sorted_vector[features_dict[p_vector[m][0]][0]]\n",
    "        sorted_vector[features_dict[p_vector[m][0]][0]] = sorted_vector[features_dict[s_vector[m][0]][0]]\n",
    "        sorted_vector[features_dict[s_vector[m][0]][0]] = temp\n",
    "             \n",
    "        temp = features_dict[p_vector[m][0]] \n",
    "        features_dict[p_vector[m][0]] = features_dict[s_vector[m][0]] \n",
    "        features_dict[s_vector[m][0]] = temp\n",
    "        \n",
    "    return sorted_vector, features_dict\n",
    "\n",
    "\n",
    "def SBS_ARFS_cs(dataset, type_cout, alpha, set_feature, name_montant, name_taux, name_duree, name_classe, cricterior, decision_tree_cs, random, cv):\n",
    "    #print(\"set_feature : \", set_feature)\n",
    "    idx_montant = dataset.columns.get_loc(name_montant)\n",
    "    idx_taux = dataset.columns.get_loc(name_taux)\n",
    "    idx_duree = dataset.columns.get_loc(name_duree)\n",
    "    \n",
    "    dataset_y = dataset[name_classe]\n",
    "    dataset_x = dataset.drop([name_classe], axis=1)\n",
    "    \n",
    "    columns = dataset.columns.tolist()\n",
    "    len_columns_ = len(columns)\n",
    "    \n",
    "    feature = deepcopy(set_feature)\n",
    "    results = dict()\n",
    "    for i in range(len(feature)):\n",
    "        diff_set = list(set(set_feature) - set([feature[i]]))\n",
    "\n",
    "        index_feature_not_selected = list(set(range(len_columns_)) - set([dataset.columns.get_loc(col) for col in set_feature]))\n",
    "        index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "        #my_tree = decision_tree_cs(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "        #accuracy, df_ = my_accuracy(test, my_tree, name_classe)\n",
    "        #result, means_scores = compute_metrics_derive(df_, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "        means_scores_, result_, accuracy_ = cross_validation_cs(dataset_x, dataset_y, decision_tree_cs, deepcopy(index_feature_not_selected), type_cout, alpha, name_classe, name_montant, name_taux, name_duree, cricterior, columns, random, cv)\n",
    "        results[i] = (means_scores_, diff_set, accuracy_, result_)\n",
    "    #print(results)\n",
    "    sorted_vector = sorted(results.items(), key=lambda x:x[1][0], reverse=False)\n",
    "    #print(sorted_vector[0][1])\n",
    "    return sorted_vector[0][1]    \n",
    "\n",
    "\n",
    "\n",
    "def zyy_feature_selection_SFS_ARFSL_cs_update_(dataset, dfv, sep, type_cout, alpha, name_columns_drop, name_classe, name_montant,\n",
    "                                                    name_taux, name_duree, cricterior, support_min=0.07, metric_v=\"confidence\", threshold_min=0.4, random=10, sbs=False, decision_tree_cs=\"decision_tree\", cv=3):\n",
    "    start = time.time()\n",
    "    divide = True\n",
    "    d = 1\n",
    "    i = d-1\n",
    "    j = 0\n",
    "    max_accuracy = float('inf')\n",
    "    sorted_vector_ = processing_feature_selection_AR_base_Multi_Loss_(dataset.copy(), dfv, cricterior, alpha, sep, name_classe, name_montant, name_taux, name_duree, support_min, metric_v, threshold_min, random, decision_tree_cs)\n",
    "    #sorted_vector = processing_feature_selection_AR_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    #654sorted_vector = processing_feature_selection_AR_Inverse_oriented_classe(dataset, dfv, sep, name_classe, support_min, metric_v, threshold_min)\n",
    "    #print(sorted_vector)\n",
    "    #quit()\n",
    "    #beta = len(sorted_vector)\n",
    "    feature_dict = dict()\n",
    "    sorted_vector = []\n",
    "    for m in range(len(sorted_vector_)):\n",
    "        sorted_vector.append(sorted_vector_[m][0])\n",
    "        feature_dict[sorted_vector_[m][0]] = (m, sorted_vector_[m][1])\n",
    "    #print(feature_dict)\n",
    "    choix = 1\n",
    "    list_vector = []\n",
    "    actual_feature_selected = []\n",
    "    check = False\n",
    "    opti_feature = dict()\n",
    "    suite_index = dict()\n",
    "    k = 0\n",
    "    feature_vector = dict()\n",
    "    extract_information = dict()\n",
    "    itera = 1\n",
    "    feature_vector[j] = deepcopy([deepcopy([]), deepcopy([])])\n",
    "    columns = dataset.columns.tolist()\n",
    "    performance_prediction = []\n",
    "        \n",
    "    print(\"sorted_vector : \", sorted_vector)\n",
    "    for m in columns:\n",
    "        performance_prediction.append(-1)\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test, columns_extract_all = preprocessing_dataset_(dataset.copy(), name_columns_drop, sep, name_classe, random)\n",
    "    \n",
    "    dataset_y = dataset[name_classe]\n",
    "    dataset_x = dataset.drop(name_columns_drop, axis=1)\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random)\n",
    "    #train = pd.concat([X_train, y_train], axis=1)\n",
    "    #test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    columns = dataset.columns.tolist()\n",
    "    len_columns = len(columns)\n",
    "    opt_tree = []\n",
    "    \n",
    "    idx_montant = dataset.columns.get_loc(name_montant)\n",
    "    idx_taux = dataset.columns.get_loc(name_taux)\n",
    "    idx_duree = dataset.columns.get_loc(name_duree)\n",
    "\n",
    "    while divide == True:\n",
    "        temp_i = -1\n",
    "        if i not in opti_feature or sorted_vector[i]:    \n",
    "            feature_vector[j][0] = sorted_vector[:i+1]\n",
    "        elif sorted_vector[i] in opti_feature[i][0]:\n",
    "            feature_vector[j][0] = sorted_vector[:i+1]\n",
    "        else:\n",
    "            feature_vector[j][0] = opti_feature[i][0]\n",
    "            feature_vector[j][0].append(sorted_vector[i])\n",
    "        if sorted_vector[i] not in feature_vector[j][1]:\n",
    "            feature_vector[j][1].append(sorted_vector[i])\n",
    "\n",
    "        #feature_vector[j][1].append(sorted_vector[i])\n",
    "  \n",
    "        print(\"i, j = \", i, \", \", j)\n",
    "        #print(\"feature_vector : \", feature_vector)\n",
    "        #data = dataset[np.concatenate((feature_vector[j], [name_classe]), axis=None)]\n",
    "        \n",
    "        #print(\"columns_extract_all : \", columns_extract_all)\n",
    "            \n",
    "        if feature_vector[j][0] != []:\n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j][0]]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "            #my_tree_gen = decision_tree_cs(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            #accuracy_gen, df_gen = my_accuracy(test, my_tree_gen, name_classe)\n",
    "            #result_gen, means_scores_gen = compute_metrics_derive(df_gen, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "            means_scores_gen, result_gen, accuracy_gen = cross_validation_cs(dataset_x, dataset_y, decision_tree_cs, deepcopy(index_feature_not_selected), type_cout, alpha, name_classe, name_montant, name_taux, name_duree, cricterior, columns, random, cv)\n",
    "\n",
    "        \n",
    "        if feature_vector[j][1] != []:\n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in feature_vector[j][1]]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "            #my_tree_sel = decision_tree_cs(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            #accuracy_sel, df_sel = my_accuracy(test, my_tree_sel, name_classe)\n",
    "            #result_sel, means_scores_sel = compute_metrics_derive(df_sel, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "            means_scores_sel, result_sel, accuracy_sel = cross_validation_cs(dataset_x, dataset_y, decision_tree_cs, deepcopy(index_feature_not_selected), type_cout, alpha, name_classe, name_montant, name_taux, name_duree, cricterior, columns, random, cv)\n",
    "           \n",
    "        \n",
    "        print(\"feature_vector[j] : \", feature_vector[j][1], \" sorted_vector[i] : \", sorted_vector[i], \" means_scores_sel : \", means_scores_sel)\n",
    "        ###addd\n",
    "        \n",
    "        if len(feature_vector[j][0]) not in opti_feature:\n",
    "            performance_prediction[len(feature_vector[j][0])-1] = means_scores_gen\n",
    "            opti_feature[len(feature_vector[j][0])] = [deepcopy(feature_vector[j][0]), means_scores_gen, len(feature_vector[j][0]), accuracy_gen, result_gen]\n",
    "            #sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(feature_vector[j][0]), feature_dict.copy())\n",
    "            #temp_i = len(feature_vector[j][0]) - 1\n",
    "        else:\n",
    "            if means_scores_gen < opti_feature[len(feature_vector[j][0])][1] and len(feature_vector[j][0])-1 in opti_feature and means_scores_gen <= opti_feature[len(feature_vector[j][0])-1][1]:\n",
    "                performance_prediction[len(feature_vector[j][0])-1] = means_scores_gen\n",
    "                opti_feature[len(feature_vector[j][0])] = [deepcopy(feature_vector[j][0]), means_scores_gen, len(feature_vector[j][0]), accuracy_gen, result_gen]\n",
    "                #sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(feature_vector[j][0]), feature_dict.copy())\n",
    "                #temp_i = len(feature_vector[j][0]) - 1\n",
    "            else:\n",
    "                if means_scores_gen < opti_feature[len(feature_vector[j][0])][1]:\n",
    "                    performance_prediction[len(feature_vector[j][0])-1] = means_scores_gen\n",
    "                    opti_feature[len(feature_vector[j][0])] = [deepcopy(feature_vector[j][0]), means_scores_gen, len(feature_vector[j][0]), accuracy_gen, result_gen]\n",
    "                    #sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(feature_vector[j][0]), feature_dict.copy())\n",
    "                    #temp_i = len(feature_vector[j][0]) - 1\n",
    "                pass\n",
    "        ########\n",
    "                        \n",
    "        if means_scores_sel < means_scores_gen:\n",
    "            means_scores = means_scores_sel\n",
    "            accuracy = accuracy_sel\n",
    "            #my_tree = my_tree_sel\n",
    "            result = result_sel\n",
    "            feature_selected = deepcopy(feature_vector[j][1])\n",
    "        else:\n",
    "            if means_scores_sel < means_scores_gen:\n",
    "                means_scores = means_scores_gen\n",
    "                accuracy = accuracy_gen\n",
    "                #my_tree = my_tree_gen\n",
    "                result = result_gen\n",
    "                feature_selected = deepcopy(feature_vector[j][0])\n",
    "            else:\n",
    "                if len(feature_vector[j][1]) >= len(feature_vector[j][0]):\n",
    "                    means_scores = means_scores_gen\n",
    "                    accuracy = accuracy_gen\n",
    "                    #my_tree = my_tree_gen\n",
    "                    result = result_gen\n",
    "                    feature_selected = deepcopy(feature_vector[j][0])\n",
    "                else:\n",
    "                    means_scores = means_scores_sel\n",
    "                    accuracy = accuracy_sel\n",
    "                    #my_tree = my_tree_sel\n",
    "                    result = result_sel\n",
    "                    feature_selected = deepcopy(feature_vector[j][1])\n",
    "\n",
    "        \n",
    "        if means_scores < max_accuracy:\n",
    "            max_accuracy = means_scores\n",
    "            #opt_tree = my_tree\n",
    "            max_scores_acc = accuracy\n",
    "            z = len(feature_selected)\n",
    "            performance_prediction[z-1] = means_scores\n",
    "            #if type(my_tree) is dict:    \n",
    "            #    feature_vector[j][1] = deepcopy(extract_feature_select_tree(my_tree))\n",
    "            opti_feature[z] = [deepcopy(feature_vector[j][1]), means_scores, len(feature_vector[j][1]), accuracy, result]       \n",
    "            feature_vector[j][1] = deepcopy(feature_selected)\n",
    "            sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(feature_selected), feature_dict.copy())\n",
    "            temp_i = z - 1\n",
    "            print(\"best value of j = \", j)\n",
    "        else:\n",
    "            feature_vector[j][1].pop(len(feature_vector[j][1])-1)\n",
    "        \n",
    "        \n",
    "        if sbs:\n",
    "            for q in range(i):\n",
    "                if q+1 in opti_feature:\n",
    "                    set_feature_use = deepcopy(opti_feature[q+1][0])                \n",
    "                    check == True\n",
    "                    while(check == True):\n",
    "                        if len(set_feature_use) > 1:\n",
    "                            scores, set_feature, accuracy_, result = SBS_ARFS_cs(dataset, type_cout, alpha, deepcopy(set_feature_use), name_montant, name_taux, name_duree, name_classe, cricterior, decision_tree_cs, random, cv)\n",
    "                            \n",
    "                            #scores, set_feature, accuracy_, result, my_tree = SBS_ARFS_cs(dataset_x, dataset_y, train, test, type_cout, alpha, deepcopy(set_feature_use), name_montant, name_taux, name_duree, name_classe, cricterior, decision_tree_cs)\n",
    "                            if len(set_feature) not in opti_feature:\n",
    "                                performance_prediction[len(set_feature)-1] = scores\n",
    "                                opti_feature[len(set_feature)] = [deepcopy(set_feature), scores, len(set_feature), accuracy_, result]\n",
    "                                #sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(set_feature), feature_dict.copy())\n",
    "                                #temp_i = len(set_feature) - 1\n",
    "                            elif scores < opti_feature[len(set_feature)][1] and len(set_feature)-1 in opti_feature and scores <= opti_feature[len(set_feature)-1][1]:\n",
    "                                performance_prediction[len(set_feature)-1] = scores\n",
    "                                opti_feature[len(set_feature)] = [deepcopy(set_feature), scores, len(set_feature), accuracy_, result]\n",
    "                                #sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(set_feature), feature_dict.copy())\n",
    "                                #temp_i = len(set_feature) - 1\n",
    "                            elif scores < opti_feature[len(set_feature)][1]:\n",
    "                                performance_prediction[len(set_feature)-1] = scores\n",
    "                                opti_feature[len(set_feature)] = [deepcopy(set_feature), scores, len(set_feature), accuracy_, result]\n",
    "                                #sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(set_feature), feature_dict.copy())\n",
    "                                #temp_i = len(set_feature) - 1\n",
    "                            else:\n",
    "                                check = False\n",
    "\n",
    "                            if scores < max_accuracy:\n",
    "                                feature_deleted = list(set(set_feature_use) - set(set_feature))\n",
    "                                feature_deleted = feature_deleted[0]\n",
    "\n",
    "                                max_accuracy = scores\n",
    "                                #opt_tree = my_tree\n",
    "                                max_scores_acc = accuracy_\n",
    "\n",
    "                                feature_vector[j][0] = deepcopy(list(set(feature_vector[j][0]) - set([feature_deleted])))\n",
    "                                feature_vector[j][1] = deepcopy(set_feature)\n",
    "                                actual_feature_selected = deepcopy(set_feature)\n",
    "                                set_feature_use = deepcopy(set_feature)\n",
    "                                z = len(set_feature)\n",
    "                                opti_feature[z] = [deepcopy(set_feature), scores, z, accuracy_, result]\n",
    "                                sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(set_feature), feature_dict.copy())\n",
    "                                temp_i = z-1\n",
    "                                performance_prediction[z-1] = scores\n",
    "                        else:\n",
    "                            check = False\n",
    "\n",
    "        for q in range(i+1):\n",
    "            if q not in opti_feature:\n",
    "                test_feature = []\n",
    "            elif q in opti_feature:\n",
    "                test_feature = deepcopy(opti_feature[q][0])\n",
    "            if sorted_vector[i] not in test_feature:\n",
    "                test_feature.append(sorted_vector[i])\n",
    "            elif sorted_vector[i] in test_feature:\n",
    "                test_feature = []\n",
    "\n",
    "            if test_feature != []:\n",
    "                index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in test_feature]))\n",
    "                index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "                #my_tree_test = decision_tree_cs(train, deepcopy(index_feature_not_selected), idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "                #accuracy_test, df_test = my_accuracy(test, my_tree_test, name_classe)\n",
    "                #result_test, means_scores_test = compute_metrics_derive(df_test, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "                means_scores_test, result_test, accuracy_test = cross_validation_cs(dataset_x, dataset_y, decision_tree_cs, deepcopy(index_feature_not_selected), type_cout, alpha, name_classe, name_montant, name_taux, name_duree, cricterior, columns, random, cv)\n",
    "\n",
    "                \n",
    "                if len(test_feature)-1 in opti_feature and len(test_feature) in opti_feature and means_scores_test < opti_feature[len(test_feature)-1][1] and means_scores_test < opti_feature[len(test_feature)][1]:\n",
    "                    performance_prediction[len(test_feature)-1] = means_scores_test\n",
    "                    opti_feature[len(test_feature)] = [deepcopy(test_feature), means_scores_test, len(test_feature), accuracy_test, result_test]\n",
    "                    #sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(test_feature), feature_dict.copy())\n",
    "                    #temp_i = len(test_feature) - 1\n",
    "                elif len(test_feature) in opti_feature and means_scores_test < opti_feature[len(test_feature)][1]:\n",
    "                    performance_prediction[len(test_feature)-1] = means_scores_test\n",
    "                    opti_feature[len(test_feature)] = [deepcopy(test_feature), means_scores_test, len(test_feature), accuracy_test, result_test]\n",
    "                    #sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(test_feature), feature_dict.copy())\n",
    "                    #temp_i = len(test_feature) - 1\n",
    "\n",
    "                if means_scores_test < max_accuracy:\n",
    "                    max_accuracy = means_scores_test\n",
    "                    \n",
    "                    #opt_tree = my_tree_test\n",
    "                    max_scores_acc = accuracy_test\n",
    "                    \n",
    "                    actual_feature_selected = deepcopy(test_feature) \n",
    "                    feature_vector[j][1] = deepcopy(test_feature)\n",
    "                    z = len(test_feature)\n",
    "                    performance_prediction[z-1] = means_scores_test\n",
    "                    opti_feature[z] = [deepcopy(test_feature), means_scores_test, z, accuracy_test, result_test]\n",
    "                    \n",
    "                    sorted_vector, feature_dict = permute_weight(deepcopy(sorted_vector), deepcopy(test_feature), feature_dict.copy())\n",
    "                    temp_i = z-1\n",
    "                                \n",
    "        \n",
    "        if temp_i != -1:\n",
    "            i = temp_i\n",
    "        #print(opti_feature)\n",
    "        if i >= len(sorted_vector)-1:\n",
    "            if j < len(feature_vector)-1:\n",
    "                sorted_vector = list_vector[j]\n",
    "                j = j + 1\n",
    "                i = suite_index[j]                \n",
    "                if i >= len(sorted_vector)-1:\n",
    "                    divide = False\n",
    "            else:\n",
    "                divide = False\n",
    "        i = i + d\n",
    "\n",
    "    for j in range(len(sorted_vector)):\n",
    "        if sorted_vector[:j] != []:\n",
    "            #X_train_selected_gen, X_test_selected_gen, columns_extract_gen = selected_dataset_(columns_extract_all, deepcopy(sorted_vector[:j]), sep, X_train.copy(), X_test.copy())\n",
    "            #means_scores_gen, conf_matrix_gen, prec_gen, feature_selected_gen = model_evaluation_SFS_(X_train_selected_gen.copy(), X_test_selected_gen.copy(), y_train.copy(), y_test.copy(), columns_extract_gen, columns, sep, cricterior)\n",
    "                        \n",
    "            index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in sorted_vector[:j]]))\n",
    "            index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "            #my_tree = decision_tree_cs(train, deepcopy(index_feature_not_selected), idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "            #accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "            #result, means_scores = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "            means_scores, result, accuracy = cross_validation_cs(dataset_x, dataset_y, decision_tree_cs, deepcopy(index_feature_not_selected), type_cout, alpha, name_classe, name_montant, name_taux, name_duree, cricterior, columns, random, cv)\n",
    "            \n",
    "            if len(sorted_vector[:j]) in opti_feature and means_scores < opti_feature[len(sorted_vector[:j])][1]:\n",
    "                performance_prediction[len(sorted_vector[:j])-1] = means_scores\n",
    "                opti_feature[len(sorted_vector[:j])] = [deepcopy(sorted_vector[:j]), means_scores, len(sorted_vector[:j]), accuracy, result]\n",
    "                if means_scores < max_accuracy:\n",
    "                    max_accuracy = means_scores\n",
    "                    #opt_tree = my_tree\n",
    "                    max_scores_acc = accuracy\n",
    "                    actual_feature_selected = deepcopy(len(sorted_vector[:j]))\n",
    "\n",
    "            if j in opti_feature:\n",
    "                if sorted_vector[j] not in opti_feature[j][0]: \n",
    "                    second_feature = deepcopy(opti_feature[j][0])\n",
    "                    second_feature.append(sorted_vector[j])\n",
    "\n",
    "                    #X_train_selected_gen, X_test_selected_gen, columns_extract_gen = selected_dataset_(columns_extract_all, deepcopy(second_feature), sep, X_train.copy(), X_test.copy())\n",
    "                    #means_scores_gen, conf_matrix_gen, prec_gen, feature_selected_gen = model_evaluation_SFS_(X_train_selected_gen.copy(), X_test_selected_gen.copy(), y_train.copy(), y_test.copy(), columns_extract_gen, columns, sep, cricterior)\n",
    "                    \n",
    "                    \n",
    "                    index_feature_not_selected = list(set(range(len_columns)) - set([dataset.columns.get_loc(col) for col in second_feature]))\n",
    "                    index_feature_not_selected = list(set(index_feature_not_selected) - set([dataset.columns.get_loc(name_classe)]))\n",
    "                    #my_tree = decision_tree_cs(train, deepcopy(index_feature_not_selected), idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "                    #accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "                    #result, means_scores = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree)\n",
    "                    means_scores, result, accuracy = cross_validation_cs(dataset_x, dataset_y, decision_tree_cs, deepcopy(index_feature_not_selected), type_cout, alpha, name_classe, name_montant, name_taux, name_duree, cricterior, columns, random, cv)\n",
    "                    \n",
    "                    \n",
    "                    if len(second_feature)-1 in opti_feature and means_scores < opti_feature[len(second_feature)-1][1] and len(second_feature) in opti_feature and means_scores < opti_feature[len(second_feature)][1]:\n",
    "                        performance_prediction[len(second_feature)-1] = means_scores\n",
    "                        opti_feature[len(second_feature)] = [deepcopy(second_feature), means_scores, len(second_feature), accuracy, result]\n",
    "                    elif len(second_feature) in opti_feature and means_scores < opti_feature[len(second_feature)][1]:\n",
    "                        performance_prediction[len(second_feature)-1] = means_scores\n",
    "                        opti_feature[len(second_feature)] = [deepcopy(second_feature), means_scores, len(second_feature), accuracy, result]\n",
    "                        \n",
    "                    if means_scores < max_accuracy:\n",
    "                        max_accuracy = means_scores\n",
    "                        #opt_tree = my_tree\n",
    "                        max_scores_acc = accuracy\n",
    "                        actual_feature_selected = deepcopy(second_feature) \n",
    "\n",
    "\n",
    "    print(\"performance_prediction : \", performance_prediction)\n",
    "    end = time.time()\n",
    "    start_ = time.time()\n",
    "    index_feature_not_selected = []\n",
    "    #my_tree = decision_tree_cs(train, index_feature_not_selected, idx_montant, idx_taux, idx_duree, min_samples=5, max_depth=5, metric=cricterior)\n",
    "    #accuracy, df = my_accuracy(test, my_tree, name_classe)\n",
    "    #results_all_data = compute_metrics_derive(df, type_cout, alpha, name_classe, name_montant, name_taux, name_duree), extract_feature_select_tree(my_tree)    \n",
    "    means_scores, result, accuracy = cross_validation_cs(dataset_x, dataset_y, decision_tree_cs, deepcopy(index_feature_not_selected), type_cout, alpha, name_classe, name_montant, name_taux, name_duree, cricterior, columns, random, cv)\n",
    "    end_ = time.time() \n",
    "    return opti_feature, max_accuracy, sorted_vector, (means_scores, result)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b76dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bbd773b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1     A2      A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  A13   A14  \\\n",
       "0     1  22.08  11.460   2   4   4  1.585   0   0    0    1    2  100  1213   \n",
       "1     0  22.67   7.000   2   8   4  0.165   0   0    0    0    2  160     1   \n",
       "2     0  29.58   1.750   1   4   4  1.250   0   0    0    1    2  280     1   \n",
       "3     0  21.67  11.500   1   5   3  0.000   1   1   11    1    2    0     1   \n",
       "4     1  20.17   8.170   2   6   4  1.960   1   1   14    0    2   60   159   \n",
       "..   ..    ...     ...  ..  ..  ..    ...  ..  ..  ...  ...  ...  ...   ...   \n",
       "685   1  31.57  10.500   2  14   4  6.500   1   0    0    0    2    0     1   \n",
       "686   1  20.67   0.415   2   8   4  0.125   0   0    0    0    2    0    45   \n",
       "687   0  18.83   9.540   2   6   4  0.085   1   0    0    0    2  100     1   \n",
       "688   0  27.42  14.500   2  14   8  3.085   1   1    1    0    2  120    12   \n",
       "689   1  41.00   0.040   2  10   4  0.040   0   1    1    0    1  560     1   \n",
       "\n",
       "     A15  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      1  \n",
       "4      1  \n",
       "..   ...  \n",
       "685    1  \n",
       "686    0  \n",
       "687    1  \n",
       "688    1  \n",
       "689    1  \n",
       "\n",
       "[690 rows x 15 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random.seed(10)\n",
    "datas = pd.read_csv('../../australian.dat',sep=' ')\n",
    "#df = datas.copy()\n",
    "#numerical_namess = ['A2', 'A7']\n",
    "#for name in numerical_namess:\n",
    "    #df[name] = pd.qcut(df[name], q=5, labels = [1, 2, 3, 4, 5], retbins = True, duplicates = 'drop')\n",
    "#    datas[name] = pd.cut(datas[name], bins=4, labels = [1, 2, 3, 4], right=True)\n",
    "\n",
    "datas = datas.dropna().reset_index(drop=True)\n",
    "#print(df.head())\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b21d52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1__0</th>\n",
       "      <th>A1__1</th>\n",
       "      <th>A2__13.75</th>\n",
       "      <th>A2__15.17</th>\n",
       "      <th>A2__15.75</th>\n",
       "      <th>A2__15.83</th>\n",
       "      <th>A2__15.92</th>\n",
       "      <th>A2__16.0</th>\n",
       "      <th>A2__16.08</th>\n",
       "      <th>A2__16.17</th>\n",
       "      <th>...</th>\n",
       "      <th>A14__15001</th>\n",
       "      <th>A14__15109</th>\n",
       "      <th>A14__18028</th>\n",
       "      <th>A14__26727</th>\n",
       "      <th>A14__31286</th>\n",
       "      <th>A14__50001</th>\n",
       "      <th>A14__51101</th>\n",
       "      <th>A14__100001</th>\n",
       "      <th>A15__0</th>\n",
       "      <th>A15__1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 1169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1__0  A1__1  A2__13.75  A2__15.17  A2__15.75  A2__15.83  A2__15.92  \\\n",
       "0        0      1          0          0          0          0          0   \n",
       "1        1      0          0          0          0          0          0   \n",
       "2        1      0          0          0          0          0          0   \n",
       "3        1      0          0          0          0          0          0   \n",
       "4        0      1          0          0          0          0          0   \n",
       "..     ...    ...        ...        ...        ...        ...        ...   \n",
       "685      0      1          0          0          0          0          0   \n",
       "686      0      1          0          0          0          0          0   \n",
       "687      1      0          0          0          0          0          0   \n",
       "688      1      0          0          0          0          0          0   \n",
       "689      0      1          0          0          0          0          0   \n",
       "\n",
       "     A2__16.0  A2__16.08  A2__16.17  ...  A14__15001  A14__15109  A14__18028  \\\n",
       "0           0          0          0  ...           0           0           0   \n",
       "1           0          0          0  ...           0           0           0   \n",
       "2           0          0          0  ...           0           0           0   \n",
       "3           0          0          0  ...           0           0           0   \n",
       "4           0          0          0  ...           0           0           0   \n",
       "..        ...        ...        ...  ...         ...         ...         ...   \n",
       "685         0          0          0  ...           0           0           0   \n",
       "686         0          0          0  ...           0           0           0   \n",
       "687         0          0          0  ...           0           0           0   \n",
       "688         0          0          0  ...           0           0           0   \n",
       "689         0          0          0  ...           0           0           0   \n",
       "\n",
       "     A14__26727  A14__31286  A14__50001  A14__51101  A14__100001  A15__0  \\\n",
       "0             0           0           0           0            0       1   \n",
       "1             0           0           0           0            0       1   \n",
       "2             0           0           0           0            0       1   \n",
       "3             0           0           0           0            0       0   \n",
       "4             0           0           0           0            0       0   \n",
       "..          ...         ...         ...         ...          ...     ...   \n",
       "685           0           0           0           0            0       0   \n",
       "686           0           0           0           0            0       1   \n",
       "687           0           0           0           0            0       0   \n",
       "688           0           0           0           0            0       0   \n",
       "689           0           0           0           0            0       0   \n",
       "\n",
       "     A15__1  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "685       1  \n",
       "686       0  \n",
       "687       1  \n",
       "688       1  \n",
       "689       1  \n",
       "\n",
       "[690 rows x 1169 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep = \"__\"\n",
    "\n",
    "columns = datas.columns\n",
    "\n",
    "dfv = pd.DataFrame()\n",
    "for col in columns:\n",
    "    dfr = pd.get_dummies(datas[col], prefix_sep=sep, prefix = col)\n",
    "    dfv = pd.concat([dfv, dfr], axis=1)\n",
    "\n",
    "dfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78fb813c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_vector :  [('A9', 42503.33164556962), ('A10', 42503.33164556962), ('A8', 64968.729483282674)]\n",
      "set_feature :  [('A7', 2526.506729166666), ('A5', 3121.4810375), ('A2', 3964.8435749999994), ('A3', 4246.265725), ('A6', 5278.441870833332), ('A4', 5412.0173625), ('A14', 5412.021425), ('A1', 5412.021425), ('A11', 5412.021425), ('A12', 5414.021425), ('A13', 9811.669745833333)]\n",
      "sorted_vector :  ['A9', 'A10', 'A8', 'A7', 'A5', 'A2', 'A3', 'A6', 'A4', 'A14', 'A1', 'A11', 'A12', 'A13']\n",
      "i, j =  0 ,  0\n",
      "feature_vector[j] :  ['A9']  sorted_vector[i] :  A9  means_scores_sel :  5399.437111666665\n",
      "best value of j =  0\n",
      "i, j =  1 ,  0\n",
      "feature_vector[j] :  ['A9', 'A10']  sorted_vector[i] :  A10  means_scores_sel :  2838.3078941666668\n",
      "best value of j =  0\n",
      "i, j =  2 ,  0\n",
      "feature_vector[j] :  ['A9', 'A10', 'A8']  sorted_vector[i] :  A8  means_scores_sel :  1711.0397933333334\n",
      "best value of j =  0\n",
      "i, j =  1 ,  0\n",
      "feature_vector[j] :  ['A8', 'A10']  sorted_vector[i] :  A10  means_scores_sel :  1711.0397933333334\n",
      "i, j =  2 ,  0\n",
      "feature_vector[j] :  ['A8', 'A9']  sorted_vector[i] :  A9  means_scores_sel :  1873.1004291666666\n",
      "i, j =  3 ,  0\n",
      "feature_vector[j] :  ['A8', 'A7']  sorted_vector[i] :  A7  means_scores_sel :  1720.0601933333332\n",
      "i, j =  4 ,  0\n",
      "feature_vector[j] :  ['A8', 'A5']  sorted_vector[i] :  A5  means_scores_sel :  1714.3045816666668\n",
      "i, j =  5 ,  0\n",
      "feature_vector[j] :  ['A8', 'A2']  sorted_vector[i] :  A2  means_scores_sel :  1701.3466933333334\n",
      "i, j =  6 ,  0\n",
      "feature_vector[j] :  ['A8', 'A3']  sorted_vector[i] :  A3  means_scores_sel :  1727.5930641666666\n",
      "i, j =  7 ,  0\n",
      "feature_vector[j] :  ['A8', 'A6']  sorted_vector[i] :  A6  means_scores_sel :  1856.0293041666666\n",
      "i, j =  8 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4']  sorted_vector[i] :  A4  means_scores_sel :  1656.3381091666668\n",
      "best value of j =  0\n",
      "i, j =  3 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A10', 'A7']  sorted_vector[i] :  A7  means_scores_sel :  1344.3686475\n",
      "i, j =  3 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A7']  sorted_vector[i] :  A8  means_scores_sel :  1330.5890474999999\n",
      "i, j =  4 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A5']  sorted_vector[i] :  A5  means_scores_sel :  1331.26619\n",
      "i, j =  5 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A2']  sorted_vector[i] :  A2  means_scores_sel :  1692.0024925\n",
      "i, j =  6 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A3']  sorted_vector[i] :  A3  means_scores_sel :  1547.5819616666665\n",
      "i, j =  7 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A6']  sorted_vector[i] :  A6  means_scores_sel :  1412.2760974999999\n",
      "i, j =  4 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A7', 'A6', 'A5']  sorted_vector[i] :  A5  means_scores_sel :  1333.4221308333333\n",
      "i, j =  5 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A7', 'A6', 'A2']  sorted_vector[i] :  A2  means_scores_sel :  1337.9803416666666\n",
      "i, j =  6 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A7', 'A6', 'A3']  sorted_vector[i] :  A3  means_scores_sel :  1360.7246958333333\n",
      "i, j =  7 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A7', 'A6', 'A10']  sorted_vector[i] :  A10  means_scores_sel :  1361.3377583333333\n",
      "i, j =  8 ,  0\n",
      "feature_vector[j] :  ['A8', 'A4', 'A7', 'A6', 'A9']  sorted_vector[i] :  A9  means_scores_sel :  1735.6092516666668\n",
      "i, j =  7 ,  0\n",
      "feature_vector[j] :  ['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A10']  sorted_vector[i] :  A10  means_scores_sel :  1348.0552308333333\n",
      "i, j =  8 ,  0\n",
      "feature_vector[j] :  ['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A3']  sorted_vector[i] :  A3  means_scores_sel :  1474.4704908333333\n",
      "i, j =  9 ,  0\n",
      "feature_vector[j] :  ['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A14']  sorted_vector[i] :  A14  means_scores_sel :  1034.1721333333332\n",
      "i, j =  10 ,  0\n",
      "feature_vector[j] :  ['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A1']  sorted_vector[i] :  A1  means_scores_sel :  1034.1721333333332\n",
      "i, j =  11 ,  0\n",
      "feature_vector[j] :  ['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A11']  sorted_vector[i] :  A11  means_scores_sel :  1617.0331899999999\n",
      "i, j =  12 ,  0\n",
      "feature_vector[j] :  ['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A12']  sorted_vector[i] :  A12  means_scores_sel :  1444.3492608333333\n",
      "i, j =  13 ,  0\n",
      "feature_vector[j] :  ['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A13']  sorted_vector[i] :  A13  means_scores_sel :  1336.4031424999998\n",
      "performance_prediction :  [1697.2601933333333, 1656.3381091666668, 1104.2335575, 1102.6748916666666, 1329.9119441666667, 1332.5282566666667, 1034.1721333333332, 1034.1721333333332, 1034.1721333333332, 1336.4031424999998, 1374.6922574999999, 1336.2381016666666, 1377.4477574999999, 1336.2381016666666, -1]\n",
      "Optimum feature :  {1: [['A8'], 1697.2601933333333, 1, 0.855072463768116, (1697.2601933333333, 0.855072463768116, 0.7865039908329382, 0.9241842448739)], 2: [['A8', 'A4'], 1656.3381091666668, 2, 0.8565217391304347, (1656.3381091666668, 0.8565217391304347, 0.7933117408906882, 0.9188962569997052)], 3: [['A8', 'A4', 'A1'], 1104.2335575, 3, 0.8405797101449275, (1104.2335575, 0.8405797101449275, 0.8144810091868916, 0.8298488484695381)], 4: [['A8', 'A4', 'A1', 'A12'], 1102.6748916666666, 4, 0.8420289855072464, (1102.6748916666666, 0.8420289855072464, 0.8331056854416486, 0.8078668266599301)], 5: [['A8', 'A4', 'A1', 'A12', 'A5'], 1329.9119441666667, 5, 0.855072463768116, (1329.9119441666667, 0.855072463768116, 0.8006501146227174, 0.8985331143951834)], 6: [['A8', 'A4', 'A1', 'A12', 'A5', 'A2'], 1332.5282566666667, 6, 0.8608695652173913, (1332.5282566666667, 0.8608695652173913, 0.8076951462589883, 0.9018053976674667)], 7: [['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9'], 1034.1721333333332, 7, 0.8666666666666667, (1034.1721333333332, 0.8666666666666667, 0.8782755600636957, 0.8142221380152415)], 8: [['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A14'], 1034.1721333333332, 8, 0.8666666666666667, (1034.1721333333332, 0.8666666666666667, 0.8782755600636957, 0.8142221380152415)], 9: [['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A14', 'A1'], 1034.1721333333332, 9, 0.8666666666666667, (1034.1721333333332, 0.8666666666666667, 0.8782755600636957, 0.8142221380152415)], 10: [['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A14', 'A1', 'A13'], 1336.4031424999998, 10, 0.8594202898550725, (1336.4031424999998, 0.8594202898550725, 0.7958513023893459, 0.9218754999789482)], 11: [['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A10', 'A3', 'A14', 'A12'], 1374.6922574999999, 11, 0.8536231884057971, (1374.6922574999999, 0.8536231884057971, 0.8055777771005498, 0.8860749021093849)], 12: [['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A10', 'A3', 'A14', 'A12', 'A13'], 1336.2381016666666, 12, 0.8536231884057971, (1336.2381016666666, 0.8536231884057971, 0.8019712487911641, 0.8959506968127657)], 13: [['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A10', 'A3', 'A14', 'A1', 'A11', 'A12'], 1377.4477574999999, 13, 0.8521739130434782, (1377.4477574999999, 0.8521739130434782, 0.8048344281177642, 0.8825034735379563)], 14: [['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A10', 'A3', 'A14', 'A1', 'A11', 'A12', 'A13'], 1336.2381016666666, 14, 0.8536231884057971, (1336.2381016666666, 0.8536231884057971, 0.8019712487911641, 0.8959506968127657)]}\n",
      "\n",
      "\n",
      "\n",
      "Sorted vector :  ['A4', 'A6', 'A7', 'A8', 'A5', 'A2', 'A9', 'A10', 'A3', 'A14', 'A1', 'A11', 'A12', 'A13']\n",
      "\n",
      "\n",
      "\n",
      "Minimal cost :  1034.1721333333332\n",
      "\n",
      "\n",
      "\n",
      "Results all data :  (1336.2381016666666, (1336.2381016666666, 0.8536231884057971, 0.8019712487911641, 0.8959506968127657))\n"
     ]
    }
   ],
   "source": [
    "# feature_selection_SFS_ARFS_Sensitive_Multi_Loss\n",
    "\n",
    "\n",
    "\n",
    "#name_classe = \"ENIMPAYEOUPAS\"\n",
    "#name_classe = \"A20\"\n",
    "name_classe = \"A15\"\n",
    "\n",
    "\n",
    "name_columns_drop = [name_classe]\n",
    "support_min = 0.4\n",
    "metric_v = \"confidence\"\n",
    "threshold_min = 0.6\n",
    "type_cout = \"pessimiste\"\n",
    "cricterior = \"pessimiste\"\n",
    "alpha = 0.0 \n",
    "global ALPHA_2\n",
    "ALPHA_2 = 0.0\n",
    "random = 3\n",
    "sbs=True\n",
    "decision_tree_cs = decision_tree_2\n",
    "cv = 5\n",
    "\n",
    "#name_montant = 'Montant'\n",
    "#name_taux = 'Taux'\n",
    "#name_duree = 'Nbreech.'\n",
    "\n",
    "#name_montant = 'A4'\n",
    "#name_taux = 'A7'\n",
    "#name_duree = 'A1'\n",
    "\n",
    "name_montant = 'A14'\n",
    "name_taux = 'A3'\n",
    "name_duree = 'A5'\n",
    "\n",
    "opti_feature, max_accuracy, sorted_vector, results_all_data = zyy_feature_selection_SFS_ARFSL_cs_update_(datas.copy(), dfv, sep, type_cout, alpha, name_columns_drop, name_classe, \n",
    "                                                name_montant, name_taux, name_duree, cricterior, support_min, metric_v, threshold_min, random, sbs, decision_tree_cs, cv)\n",
    "\n",
    "print(\"Optimum feature : \", opti_feature) \n",
    "print(\"\\n\\n\")\n",
    "print(\"Sorted vector : \", sorted_vector)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Minimal cost : \", max_accuracy)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Results all data : \", results_all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51fe1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_vector :  [('A12', 41304.6816), ('A9', 42503.33164556962), ('A10', 42503.33164556962), ('A8', 64968.729483282674)]\n",
      "set_feature :  [('A7', 2526.506729166666), ('A5', 3121.4810375), ('A2', 3964.8435749999994), ('A3', 4246.265725), ('A6', 5278.441870833332), ('A4', 5412.0173625), ('A14', 5412.021425), ('A1', 5412.021425), ('A11', 5412.021425), ('A13', 9811.669745833333)]\n",
      "sorted_vector :  ['A12', 'A9', 'A10', 'A8', 'A7', 'A5', 'A2', 'A3', 'A6', 'A4', 'A14', 'A1', 'A11', 'A13']\n",
      "i, j =  0 ,  0\n",
      "feature_vector[j] :  ['A12']  sorted_vector[i] :  A12  means_scores_sel :  4655.461887499999\n",
      "best value of j =  0\n",
      "i, j =  1 ,  0\n",
      "feature_vector[j] :  ['A12', 'A9']  sorted_vector[i] :  A9  means_scores_sel :  5400.237111666665\n",
      "i, j =  2 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10']  sorted_vector[i] :  A10  means_scores_sel :  2836.152394166667\n",
      "best value of j =  0\n",
      "i, j =  2 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A9']  sorted_vector[i] :  A9  means_scores_sel :  2836.152394166667\n",
      "i, j =  3 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8']  sorted_vector[i] :  A8  means_scores_sel :  1706.9545025\n",
      "best value of j =  0\n",
      "i, j =  3 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A9']  sorted_vector[i] :  A9  means_scores_sel :  1706.9545025\n",
      "i, j =  4 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A7']  sorted_vector[i] :  A7  means_scores_sel :  1730.3376691666667\n",
      "i, j =  5 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A5']  sorted_vector[i] :  A5  means_scores_sel :  1723.1213216666667\n",
      "i, j =  6 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A2']  sorted_vector[i] :  A2  means_scores_sel :  1710.8235025\n",
      "i, j =  7 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A3']  sorted_vector[i] :  A3  means_scores_sel :  1743.26479\n",
      "i, j =  8 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A6']  sorted_vector[i] :  A6  means_scores_sel :  1729.1228008333333\n",
      "i, j =  9 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4']  sorted_vector[i] :  A4  means_scores_sel :  1339.8700233333334\n",
      "best value of j =  0\n",
      "i, j =  4 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4', 'A7']  sorted_vector[i] :  A7  means_scores_sel :  1340.2700233333333\n",
      "i, j =  5 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4', 'A5']  sorted_vector[i] :  A5  means_scores_sel :  1356.6368425\n",
      "i, j =  6 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4', 'A2']  sorted_vector[i] :  A2  means_scores_sel :  1344.1390233333332\n",
      "i, j =  7 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4', 'A3']  sorted_vector[i] :  A3  means_scores_sel :  1376.5936441666665\n",
      "i, j =  8 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4', 'A6']  sorted_vector[i] :  A6  means_scores_sel :  1362.6391341666667\n",
      "i, j =  9 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4']  sorted_vector[i] :  A12  means_scores_sel :  1339.8700233333334\n",
      "i, j =  8 ,  0\n",
      "feature_vector[j] :  ['A10', 'A8', 'A9', 'A4', 'A7', 'A5', 'A2', 'A12', 'A6']  sorted_vector[i] :  A6  means_scores_sel :  1339.1161433333332\n",
      "i, j =  9 ,  0\n",
      "feature_vector[j] :  ['A10', 'A8', 'A9', 'A4', 'A7', 'A5', 'A2', 'A12', 'A3']  sorted_vector[i] :  A3  means_scores_sel :  1374.6922574999999\n",
      "i, j =  10 ,  0\n",
      "feature_vector[j] :  ['A10', 'A8', 'A9', 'A4', 'A7', 'A5', 'A2', 'A12', 'A14']  sorted_vector[i] :  A14  means_scores_sel :  1339.1161433333332\n",
      "i, j =  11 ,  0\n",
      "feature_vector[j] :  ['A10', 'A8', 'A9', 'A4', 'A7', 'A5', 'A2', 'A12', 'A1']  sorted_vector[i] :  A1  means_scores_sel :  1339.1294766666665\n",
      "i, j =  12 ,  0\n",
      "feature_vector[j] :  ['A10', 'A8', 'A9', 'A4', 'A7', 'A5', 'A2', 'A12', 'A11']  sorted_vector[i] :  A11  means_scores_sel :  1355.6411433333333\n",
      "i, j =  5 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4', 'A11', 'A5']  sorted_vector[i] :  A5  means_scores_sel :  1345.9630658333333\n",
      "i, j =  6 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4', 'A11', 'A2']  sorted_vector[i] :  A2  means_scores_sel :  1356.2376433333334\n",
      "i, j =  7 ,  0\n",
      "feature_vector[j] :  ['A12', 'A10', 'A8', 'A4', 'A11', 'A7']  sorted_vector[i] :  A7  means_scores_sel :  1338.3991433333333\n",
      "i, j =  8 ,  0\n",
      "feature_vector[j] :  ['A9', 'A8', 'A11', 'A4', 'A12', 'A5', 'A2', 'A7', 'A6']  sorted_vector[i] :  A6  means_scores_sel :  1226.24597\n",
      "i, j =  8 ,  0\n",
      "feature_vector[j] :  ['A9', 'A8', 'A11', 'A4', 'A12', 'A5', 'A2', 'A6', 'A7']  sorted_vector[i] :  A7  means_scores_sel :  1226.24597\n",
      "i, j =  9 ,  0\n",
      "feature_vector[j] :  ['A9', 'A8', 'A11', 'A4', 'A12', 'A5', 'A2', 'A6', 'A3']  sorted_vector[i] :  A3  means_scores_sel :  1636.3022583333334\n",
      "i, j =  10 ,  0\n",
      "feature_vector[j] :  ['A9', 'A8', 'A11', 'A4', 'A12', 'A5', 'A2', 'A6', 'A14']  sorted_vector[i] :  A14  means_scores_sel :  1226.24247\n",
      "i, j =  11 ,  0\n",
      "feature_vector[j] :  ['A9', 'A8', 'A11', 'A4', 'A12', 'A5', 'A2', 'A6', 'A1']  sorted_vector[i] :  A1  means_scores_sel :  1226.2558033333332\n",
      "i, j =  12 ,  0\n",
      "feature_vector[j] :  ['A9', 'A8', 'A11', 'A4', 'A12', 'A5', 'A2', 'A6', 'A10']  sorted_vector[i] :  A10  means_scores_sel :  1355.6376433333332\n",
      "i, j =  13 ,  0\n",
      "feature_vector[j] :  ['A9', 'A8', 'A11', 'A4', 'A12', 'A5', 'A2', 'A6', 'A13']  sorted_vector[i] :  A13  means_scores_sel :  1335.6547683333333\n",
      "performance_prediction :  [2825.2157, 1714.3045816666668, 1706.9545025, 1339.8700233333334, 1331.9586633333333, 1337.8124766666667, 1226.24247, 1226.24247, 1226.24247, 1226.2558033333332, 1335.6547683333333, 1374.6922574999999, 1336.2381016666666, 1336.2381016666666, -1]\n"
     ]
    }
   ],
   "source": [
    "# feature_selection_SFS_ARFS_Sensitive_Multi_Loss\n",
    "\n",
    "\n",
    "\n",
    "#name_classe = \"ENIMPAYEOUPAS\"\n",
    "#name_classe = \"A20\"\n",
    "name_classe = \"A15\"\n",
    "\n",
    "\n",
    "name_columns_drop = [name_classe]\n",
    "support_min = 0.4\n",
    "metric_v = \"confidence\"\n",
    "threshold_min = 0.4\n",
    "type_cout = \"pessimiste\"\n",
    "cricterior = \"pessimiste\"\n",
    "alpha = 0.0 \n",
    "global ALPHA_2\n",
    "ALPHA_2 = 0.0\n",
    "random = 3\n",
    "sbs=True\n",
    "decision_tree_cs = decision_tree_2\n",
    "cv = 5\n",
    "\n",
    "#name_montant = 'Montant'\n",
    "#name_taux = 'Taux'\n",
    "#name_duree = 'Nbreech.'\n",
    "\n",
    "#name_montant = 'A4'\n",
    "#name_taux = 'A7'\n",
    "#name_duree = 'A1'\n",
    "\n",
    "name_montant = 'A14'\n",
    "name_taux = 'A3'\n",
    "name_duree = 'A5'\n",
    "\n",
    "opti_feature, max_accuracy, sorted_vector, results_all_data = zyy_feature_selection_SFS_ARFSL_cs_update_(datas.copy(), dfv, sep, type_cout, alpha, name_columns_drop, name_classe, \n",
    "                                                name_montant, name_taux, name_duree, cricterior, support_min, metric_v, threshold_min, random, sbs, decision_tree_cs, cv)\n",
    "\n",
    "print(\"Optimum feature : \", opti_feature) \n",
    "print(\"\\n\\n\")\n",
    "print(\"Sorted vector : \", sorted_vector)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Minimal cost : \", max_accuracy)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Results all data : \", results_all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ff2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "4, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079dd73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
